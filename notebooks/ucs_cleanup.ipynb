{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd25808",
   "metadata": {},
   "source": [
    "# UCS Data Pipeline: Standardization & Normalization\n",
    "\n",
    "**Dataset:** Union of Concerned Scientists (UCS) Satellite Database  \n",
    "**Objective:** Prepare active satellite registry data for merger with SATCAT.\n",
    "\n",
    "### **The Engineering Challenge**\n",
    "The UCS database is human-maintained, leading to significant inconsistencies in categorical fields. To make this data machine-readable for our \"Kessler Syndrome\" analysis, we must implement a strict cleaning pipeline:\n",
    "1.  **Ingestion & Sanitization:** Load raw data and neutralize whitespace/character artifacts.\n",
    "2.  **Normalization:** Standardize \"Country of Operator\" and \"Users\" to ensure categorical consistency.\n",
    "3.  **Physical Validation:** Enforce orbital mechanics constraints (e.g., Apogee vs. Perigee).\n",
    "4.  **Mass Imputation:** Address missing values using the \"ISS Exception\" and grouped median fills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18a042",
   "metadata": {},
   "source": [
    "### **Stage 1: Ingestion & String Sanitization**\n",
    "**The Problem:** Raw human-maintained data often contains hidden whitespace and character artifacts (e.g., \" USA \" vs \"USA\"), which causes silent failures during categorical grouping.\n",
    "\n",
    "**The Solution:** Use a **lambda-based stripping** operation to strictly trim whitespace from all text-based columns and headers, ensuring a clean baseline for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucs_sats_messy = pd.read_csv('../data/original/UCS-Satellite-Database 5-1-2023.csv')\n",
    "text_cols = ucs_sats_messy.select_dtypes(['object']).columns\n",
    "\n",
    "ucs_sats_messy[text_cols] = ucs_sats_messy[text_cols].apply(lambda x: x.str.strip())\n",
    "ucs_sats_messy.columns = ucs_sats_messy.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85856d1c",
   "metadata": {},
   "source": [
    "### **Stage 1.1: Strategic Feature Selection**\n",
    "**The Problem:** The raw UCS export contains numerous unpopulated placeholders (e.g., `Unnamed` columns) created by formatting artifacts in the original Excel file. These \"Ghost Columns\" inflate memory usage without adding information.\n",
    "\n",
    "**The Solution:** Implement a **dynamic filter** to identify and drop all columns matching the `Unnamed` pattern, effectively sanitizing the dataframe structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7358975",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnamed_columns_dropped = [col for col in ucs_sats_messy.columns if 'Unnamed' in col]\n",
    "\n",
    "if unnamed_columns_dropped:\n",
    "    ucs_sats_messy.drop(columns=unnamed_columns_dropped, inplace=True)\n",
    "    print(f\"Dropped {len(unnamed_columns_dropped)} artifact columns (e.g., {unnamed_columns_dropped[0]}).\")\n",
    "else:\n",
    "    print(\"No artifact columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af691d3c",
   "metadata": {},
   "source": [
    "### **Stage 2: Enforcing Orbital Mechanics**\n",
    "**The Problem:** Observational errors can result in physically impossible trajectories (Apogee < Perigee), and raw data often contains formatting artifacts (commas) that prevent numeric analysis.\n",
    "\n",
    "**The Solution:**\n",
    "* **Sanitize Numerics:** Remove string delimiters (commas) from `Perigee` and `Apogee`.\n",
    "* **Physical Validation:** Implement a logical filter to ensure **Apogee (km) >= Perigee (km)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f0ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitize Numerics (Remove commas from strings)\n",
    "ucs_sats_messy['Perigee (km)'] = ucs_sats_messy['Perigee (km)'].astype(str).str.replace(',', '', regex=False)\n",
    "ucs_sats_messy['Apogee (km)'] = ucs_sats_messy['Apogee (km)'].astype(str).str.replace(',', '', regex=False)\n",
    "\n",
    "# Convert to Float (Coerce errors to NaN)\n",
    "ucs_sats_messy['Perigee (km)'] = pd.to_numeric(ucs_sats_messy['Perigee (km)'], errors='coerce')\n",
    "ucs_sats_messy['Apogee (km)'] = pd.to_numeric(ucs_sats_messy['Apogee (km)'], errors='coerce')\n",
    "\n",
    "# Drop missing values (We can't check physics if numbers are missing)\n",
    "ucs_sats_messy.dropna(subset=['Perigee (km)', 'Apogee (km)'], inplace=True)\n",
    "\n",
    "print(\"--- PRE-PATCH DIAGNOSTIC ---\")\n",
    "impossible_orbits = ucs_sats_messy[ucs_sats_messy['Apogee (km)'] < ucs_sats_messy['Perigee (km)']]\n",
    "print(f\"Satellites Violating Physics: {len(impossible_orbits)}\")\n",
    "\n",
    "if not impossible_orbits.empty:\n",
    "    print(\"Violations Found:\")\n",
    "    print(impossible_orbits[['Name of Satellite, Alternate Names', 'Apogee (km)', 'Perigee (km)']].head(5))\n",
    "\n",
    "# Fix known typo for Yaogan 35-5-1 (49.0 -> 499.0)\n",
    "print(\"\\n... Applying Manual Patch for Yaogan 35-5-1 ...\\n\")\n",
    "typo_mask = ucs_sats_messy['Name of Satellite, Alternate Names'] == 'Yaogan 35-5-1'\n",
    "ucs_sats_messy.loc[typo_mask, 'Apogee (km)'] = 499.0\n",
    "\n",
    "print(\"--- POST-PATCH DIAGNOSTIC ---\")\n",
    "impossible_orbits_after = ucs_sats_messy[ucs_sats_messy['Apogee (km)'] < ucs_sats_messy['Perigee (km)']]\n",
    "print(f\"Satellites Violating Physics: {len(impossible_orbits_after)}\")\n",
    "\n",
    "if impossible_orbits_after.empty:\n",
    "    print(\"‚úÖ SUCCESS: All physics violations resolved.\")\n",
    "\n",
    "# Only keeps valid rows. Since we fixed the error, we lose 0 satellites here.\n",
    "ucs_sats_messy = ucs_sats_messy[ucs_sats_messy['Apogee (km)'] >= ucs_sats_messy['Perigee (km)']]\n",
    "\n",
    "print(f\"\\nTotal Satellites Retained: {len(ucs_sats_messy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd4e9b",
   "metadata": {},
   "source": [
    "### **Stage 3: Metadata Decoupling (Source Preservation)**\n",
    "**The Problem:** Carrying extensive \"Comments\" and \"Source\" columns creates \"Wide Data\" that is inefficient for large-scale physics modeling.\n",
    "\n",
    "**The Solution:**\n",
    "* **Source Archive:** Extract and save metadata into a secondary file (`ucs_dropped.csv`).\n",
    "* **Relational Key:** Retain the `norad_id` as a primary key to allow for future re-integration of this context if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2386333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define this list so we never accidentally drop something we didn't save\n",
    "archived_columns = [\n",
    "    'Source Used for Orbital Data', 'Source', 'Source.1', 'Source.2', \n",
    "    'Source.3', 'Source.4', 'Source.5', 'Source.6', 'Comments'\n",
    "]\n",
    "\n",
    "# We grab exactly the columns defined above\n",
    "sources = ucs_sats_messy[archived_columns].copy()\n",
    "\n",
    "# We insert the 'norad_id' now so it matches the future clean dataset\n",
    "sources.insert(0, 'norad_id', ucs_sats_messy['NORAD Number'])\n",
    "\n",
    "# 4. Save metadata into a secondary file, ucs_dropped.csv\n",
    "sources = sources.sort_values(by='norad_id')\n",
    "sources.to_csv('../data/clean/ucs_dropped.csv', index=False)\n",
    "print(f\"Archived {sources.shape[1]} columns to 'ucs_dropped.csv'\")\n",
    "\n",
    "# Use the archived_columns varible we defined earlier to drop only what weve already exported.\n",
    "ucs_sats_messy.drop(columns=archived_columns, inplace=True)\n",
    "\n",
    "print(f\"Dropped {len(archived_columns)} columns from active memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d66bd3",
   "metadata": {},
   "source": [
    "### **Stage 3.1: Categorical and Temporal Sanitization**\n",
    "**The Problem:** Mixed-case strings in orbital classifications and string-formatted dates prevent accurate grouping and time-series analysis.\n",
    "\n",
    "**The Solution:**\n",
    "* **Case Normalization:** Force `Class of Orbit` to uppercase to ensure \"LEO\" and \"leo\" are treated as a single category.\n",
    "* **Temporal Conversion:** Parse `Date of Launch` into standard datetime objects to support historical trend modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucs_sats_messy['Class of Orbit'] = ucs_sats_messy['Class of Orbit'].str.upper()\n",
    "ucs_sats_messy['Date of Launch'] = pd.to_datetime(ucs_sats_messy['Date of Launch'], errors='coerce')\n",
    "ucs_sats_messy = ucs_sats_messy.dropna(subset=['Date of Launch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2f409",
   "metadata": {},
   "source": [
    "### **Stage 3.2: Universal Numeric Sanitization (The Physics 10)**\n",
    "\n",
    "**The Problem:** High-fidelity physics modeling requires strict numeric types. However, fields like `Launch Mass`, `Period`, and `Perigee` often contain human-entered string artifacts‚Äîsuch as commas in \"1,200\" or non-numeric notes‚Äîthat force Pandas to treat the entire column as an `object` (string).\n",
    "\n",
    "**The Solution:**\n",
    "* **Neutralize Delimiters:** Implement a universal string-replacement loop to strip commas across all 10 key physics columns.\n",
    "* **Type Enforcement:** Utilize `pd.to_numeric` with `errors='coerce'`. This gracefully handles irregular entries (e.g., \"15 years\" or \"~500\") by converting them to `NaN`, ensuring the data is mathematically valid for Stage 4 calculations.\n",
    "* **Immediate Diagnostic:** Execute a type-verification audit to confirm that every physics field has transitioned to `float64`.\n",
    "\n",
    "**Impact:** This ensures that the \"Physics Reconstruction Engine\" in the next stage has a stable, purely numeric foundation to work from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of columns that must be numeric\n",
    "columns_to_sanitize = [\n",
    "    'Launch Mass (kg.)', \n",
    "    'Dry Mass (kg.)', \n",
    "    'Power (watts)',\n",
    "    'Period (minutes)',\n",
    "    'Expected Lifetime (yrs.)',\n",
    "    'Perigee (km)',\n",
    "    'Apogee (km)',\n",
    "    'Eccentricity',\n",
    "    'Inclination (degrees)',\n",
    "    'Longitude of GEO (degrees)'\n",
    "]\n",
    "\n",
    "print(f\"Sanitizing {len(columns_to_sanitize)} physics columns...\")\n",
    "\n",
    "# THE CLEANING LOOP\n",
    "for col in columns_to_sanitize:\n",
    "    if col in ucs_sats_messy.columns:\n",
    "        # Force to string, remove commas, and coerce to float\n",
    "        ucs_sats_messy[col] = ucs_sats_messy[col].astype(str).str.replace(',', '', regex=False)\n",
    "        ucs_sats_messy[col] = pd.to_numeric(ucs_sats_messy[col], errors='coerce')\n",
    "\n",
    "print(\"Numeric Sanitization Complete.\")\n",
    "\n",
    "# IMMEDIATE VERIFICATION (Diagnostic)\n",
    "print(f\"\\n{'Column (Original Name)':<30} | {'Current Type':<15} | {'Sample Value':<15} | {'Count'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for col in columns_to_sanitize:\n",
    "    if col in ucs_sats_messy.columns:\n",
    "        dtype = str(ucs_sats_messy[col].dtype)\n",
    "        # Get a sample value (first non-null)\n",
    "        sample = ucs_sats_messy[col].dropna().iloc[0] if not ucs_sats_messy[col].dropna().empty else \"Empty\"\n",
    "        count = ucs_sats_messy[col].count()\n",
    "        # VISUAL ALARM: If it's an object, mark it with '!!!'\n",
    "        # We want to see 'float64' or 'int64'. 'object' is a failure.\n",
    "        status_marker = \"!!!\" if 'object' in dtype else \"\"\n",
    "        \n",
    "        print(f\"{col:<30} | {dtype:<15} | {sample:<15} | {count} {status_marker}\")\n",
    "    else:\n",
    "        print(f\"{col:<30} | NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc22e4",
   "metadata": {},
   "source": [
    "### **Stage 3.3: Identifier Sanitization (Merge Key Prep)**\n",
    "**The Problem:** The `COSPAR Number` and `NORAD Number` columns often contain leading/trailing whitespace or inconsistent string types, which can cause \"Silent Failures\" during dataset merges.\n",
    "\n",
    "**The Solution:** Strip all whitespace and enforce a consistent string format across all primary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sanitizing primary identifiers...\")\n",
    "\n",
    "# Clean COSPAR IDs (Removing the leading spaces found in the audit)\n",
    "# We use astype(str) to ensure we can use string methods, then strip and uppercase.\n",
    "ucs_sats_messy['COSPAR Number'] = ucs_sats_messy['COSPAR Number'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Clean NORAD IDs (Ensuring they are clean strings for the merge)\n",
    "ucs_sats_messy['NORAD Number'] = ucs_sats_messy['NORAD Number'].astype(str).str.strip()\n",
    "\n",
    "# Re-neutralize 'nan' strings\n",
    "# astype(str) converts actual NaNs into the literal string 'nan'. We fix that here.\n",
    "ucs_sats_messy['COSPAR Number'] = ucs_sats_messy['COSPAR Number'].replace('NAN', np.nan)\n",
    "ucs_sats_messy['NORAD Number'] = ucs_sats_messy['NORAD Number'].replace('NAN', np.nan)\n",
    "\n",
    "print(\"Identifier Sanitization Complete: Merge keys are whitespace-free.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af062cb6",
   "metadata": {},
   "source": [
    "### **Verification: Intermediate Pipeline Audit (The Quality Gate)**\n",
    "\n",
    "**Objective:** This audit serves as a critical \"Quality Gate\" to verify the structural integrity of the dataframe before it enters the Stage 4 Physics Reconstruction Engine. \n",
    "\n",
    "**Validation Targets:**\n",
    "1.  **Relational Integrity:** Confirm `Source` metadata was successfully decoupled and archived to `ucs_dropped.csv`.\n",
    "2.  **Memory Optimization:** Ensure \"Ghost Columns\" and non-essential strings are purged to maintain a \"Lean\" modeling environment.\n",
    "3.  **Type Enforcement:** Confirm that mathematical fields (Perigee, Apogee, Mass) have been successfully sanitized of string artifacts and are ready for calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07acafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structural Check: Ghost & Metadata Columns\n",
    "remaining_unnamed = [col for col in ucs_sats_messy.columns if 'Unnamed' in col]\n",
    "metadata_to_check = [\n",
    "    'Source Used for Orbital Data', 'Source', 'Source.1', 'Source.2', \n",
    "    'Source.3', 'Source.4', 'Source.5', 'Source.6', 'Comments'\n",
    "]\n",
    "remaining_metadata = [col for col in metadata_to_check if col in ucs_sats_messy.columns]\n",
    "\n",
    "# Type Check: Comprehensive Physics Scan\n",
    "# We check a subset of critical fields to ensure Stage 3.2 worked across the board\n",
    "physics_cols = ['Perigee (km)', 'Apogee (km)', 'Launch Mass (kg.)']\n",
    "physics_status = all(pd.api.types.is_numeric_dtype(ucs_sats_messy[col]) for col in physics_cols)\n",
    "\n",
    "# Relational Check: Identifier Whitespace\n",
    "# We verify Stage 3.3 by checking if any NORAD ID still has a space\n",
    "space_check = ucs_sats_messy['NORAD Number'].str.contains(' ').any()\n",
    "\n",
    "print(f\"{'--- INTERMEDIATE PIPELINE AUDIT ---':^45}\")\n",
    "print(f\"{'CHECK':<25} | {'STATUS'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Report Ghost Columns\n",
    "ghost_status = \"‚úÖ CLEAN\" if not remaining_unnamed else f\"‚ùå FOUND: {len(remaining_unnamed)}\"\n",
    "print(f\"{'Ghost Column Purge':<25} | {ghost_status}\")\n",
    "\n",
    "# Report Metadata Purge\n",
    "meta_status = \"‚úÖ SUCCESS\" if not remaining_metadata else \"‚ùå FAILED\"\n",
    "print(f\"{'Metadata Archive':<25} | {meta_status}\")\n",
    "\n",
    "# Report Physics Typing\n",
    "type_status = \"‚úÖ NUMERIC\" if physics_status else \"‚ùå STRING ERROR\"\n",
    "print(f\"{'Physics Type Enforcement':<25} | {type_status}\")\n",
    "\n",
    "# Report ID Sanitization (Whitespace check)\n",
    "id_status = \"‚úÖ WHITESPACE-FREE\" if not space_check else \"‚ùå SPACE DETECTED\"\n",
    "print(f\"{'Identifier Sanitization':<25} | {id_status}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(f\"Final Pre-Imputation Count: {len(ucs_sats_messy):,} satellites\")\n",
    "\n",
    "# Final logic gate: Stop the user if something is fundamentally broken\n",
    "if not physics_status or space_check:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Quality Gate failed. Review Stage 3 before proceeding.\")\n",
    "else:\n",
    "    print(\"\\nüöÄ PASS: Dataset is officially Physics-Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79cd413",
   "metadata": {},
   "source": [
    "### **Stage 4.1: Addressing the Physics Transparency Gap (Mass & Power)**\n",
    "**The Problem:** Critical physical properties (`Launch Mass`, `Dry Mass`, `Power`) are missing for significant portions of the registry. Deleting these rows would hide risk; leaving them empty breaks kinetic modeling.\n",
    "\n",
    "**The Solution:**\n",
    "* **The \"White Whale\" Exception:** Manually set the **ISS** mass (450,000 kg) to prevent it from skewing statistical medians.\n",
    "* **Grouped Median Imputation:** Fill `Launch Mass` and `Power` using the median of satellites with similar **Orbit** and **Purpose**.\n",
    "* **Physics-Informed Ratio:** Derive `Dry Mass` by calculating the typical *Dry-to-Wet Ratio* for each orbit class and applying it to the satellite's launch mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd02f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ISS EXCEPTION (THE \"WHITE WHALE\")\n",
    "# We manually set the station mass first because it is a unique outlier.\n",
    "# We use '25544' as a string to match the Stage 3.3 sanitization and create our mask to make things easier.\n",
    "iss_mask = ucs_sats_messy['NORAD Number'] == '25544'\n",
    "\n",
    "ucs_sats_messy.loc[iss_mask, 'Launch Mass (kg.)'] = 450000\n",
    "ucs_sats_messy.loc[iss_mask, 'Power (watts)'] = 84000\n",
    "ucs_sats_messy.loc[iss_mask, 'Dry Mass (kg.)'] = 420000\n",
    "\n",
    "print(f\"ISS (NORAD 25544) manually patched: 450,000kg Mass | 420,000kg Dry | 84kW Power\")\n",
    "\n",
    "# IMPUTE LAUNCH MASS & POWER (GROUPED MEDIANS)\n",
    "# Logic: Satellites with the same mission (Purpose) in the same region (Class of Orbit) \n",
    "# usually share similar chassis types (e.g., Starlink, OneWeb).\n",
    "print(\"Imputing Launch Mass & Power via Grouped Medians...\")\n",
    "fill_cols = ['Launch Mass (kg.)', 'Power (watts)']\n",
    "\n",
    "for col in fill_cols:\n",
    "    # Calculate medians based on the specific peer group\n",
    "    medians = ucs_sats_messy.groupby(['Class of Orbit', 'Purpose'])[col].transform('median')\n",
    "    ucs_sats_messy[col] = ucs_sats_messy[col].fillna(medians)\n",
    "\n",
    "# Orbit Fallback for Mass\n",
    "orbit_medians_mass = ucs_sats_messy.groupby('Class of Orbit')['Launch Mass (kg.)'].transform('median')\n",
    "ucs_sats_messy['Launch Mass (kg.)'] = ucs_sats_messy['Launch Mass (kg.)'].fillna(orbit_medians_mass)\n",
    "\n",
    "# Orbit Fallback for Power\n",
    "orbit_medians_pwr = ucs_sats_messy.groupby('Class of Orbit')['Power (watts)'].transform('median')\n",
    "ucs_sats_messy['Power (watts)'] = ucs_sats_messy['Power (watts)'].fillna(orbit_medians_pwr)\n",
    "\n",
    "# Global Fallback for Mass (The Absolute Safety Net)\n",
    "global_mass_median = ucs_sats_messy['Launch Mass (kg.)'].median()\n",
    "ucs_sats_messy['Launch Mass (kg.)'] = ucs_sats_messy['Launch Mass (kg.)'].fillna(global_mass_median)\n",
    "\n",
    "# Global Fallback for Power (The Absolute Safety Net)\n",
    "global_power_median = ucs_sats_messy['Power (watts)'].median()\n",
    "ucs_sats_messy['Power (watts)'] = ucs_sats_messy['Power (watts)'].fillna(global_power_median)\n",
    "\n",
    "# IMPUTE DRY MASS (RATIO-DERIVED)\n",
    "# We cannot use simple medians for Dry Mass because a 1kg CubeSat shouldn't \n",
    "# receive a 1,000kg median mass. We use the structural ratio instead.\n",
    "print(\"Imputing Dry Mass via Orbit-Specific Mass Ratios...\")\n",
    "\n",
    "# Calculate existing ratios (Dry Mass / Launch Mass)\n",
    "ucs_sats_messy['mass_ratio'] = ucs_sats_messy['Dry Mass (kg.)'] / ucs_sats_messy['Launch Mass (kg.)']\n",
    "\n",
    "# Get the median ratio for each orbit (e.g., LEO sats vs. massive GEO commsats)\n",
    "ratio_medians = ucs_sats_messy.groupby('Class of Orbit')['mass_ratio'].transform('median')\n",
    "ucs_sats_messy['mass_ratio'] = ucs_sats_messy['mass_ratio'].fillna(ratio_medians)\n",
    "\n",
    "# Apply the ratio to the specific satellite's actual Launch Mass\n",
    "estimated_dry_mass = ucs_sats_messy['Launch Mass (kg.)'] * ucs_sats_messy['mass_ratio']\n",
    "ucs_sats_messy['Dry Mass (kg.)'] = ucs_sats_messy['Dry Mass (kg.)'].fillna(estimated_dry_mass)\n",
    "\n",
    "# Drop the temporary ratio column\n",
    "ucs_sats_messy.drop(columns=['mass_ratio'], inplace=True)\n",
    "\n",
    "# 5. FINAL PHYSICS AUDIT\n",
    "print(\"\\n--- Physics Gap Audit (Remaining Missing Values) ---\")\n",
    "print(f\"Launch Mass: {ucs_sats_messy['Launch Mass (kg.)'].isnull().sum()}\")\n",
    "print(f\"Dry Mass:    {ucs_sats_messy['Dry Mass (kg.)'].isnull().sum()}\")\n",
    "print(f\"Power:       {ucs_sats_messy['Power (watts)'].isnull().sum()}\")\n",
    "\n",
    "# Visual Verification of the ISS\n",
    "display(ucs_sats_messy[iss_mask][['Name of Satellite, Alternate Names', 'Launch Mass (kg.)', 'Power (watts)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057e0bc",
   "metadata": {},
   "source": [
    "### **Stage 4.2: Orbital & Lifecycle Sweep (The Final Gaps)**\n",
    "\n",
    "**The Problem:** Secondary gaps in orbital elements (`Period`) and operational data (`Expected Lifetime`) prevent a total kinetic and temporal model.\n",
    "\n",
    "**The Solution:**\n",
    "1.  **Keplerian Derivation:** Use Kepler‚Äôs Third Law to mathematically calculate missing **Orbital Periods** from existing Perigee/Apogee data.\n",
    "2.  **Lifecycle Imputation:** Fill missing **Expected Lifetimes** using medians grouped by `Class of Orbit`.\n",
    "3.  **The \"Dense\" Registry:** Apply a final median sweep to ensure all 10 physics columns have 0 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Executing Final Physics Sweep...\")\n",
    "\n",
    "# Kepler's Third Law (Calculating Period from Altitude)\n",
    "# Formula: T = 2 * pi * sqrt(a^3 / mu)\n",
    "# semi-major axis (a) = Earth_Radius + (Perigee + Apogee) / 2\n",
    "earth_radius = 6378.137\n",
    "mu = 398600.4418 # Earth's gravitational parameter (km^3/s^2)\n",
    "\n",
    "def calculate_period(row):\n",
    "    # Only calculate if Period is missing but we have altitudes\n",
    "    if pd.isna(row['Period (minutes)']) and not pd.isna(row['Perigee (km)']) and not pd.isna(row['Apogee (km)']):\n",
    "        # a is the semi-major axis in km\n",
    "        a = earth_radius + ((row['Perigee (km)'] + row['Apogee (km)']) / 2)\n",
    "        period_seconds = 2 * np.pi * np.sqrt(a**3 / mu)\n",
    "        return period_seconds / 60\n",
    "    return row['Period (minutes)']\n",
    "\n",
    "# Apply the physics derivation\n",
    "ucs_sats_messy['Period (minutes)'] = ucs_sats_messy.apply(calculate_period, axis=1)\n",
    "\n",
    "# Impute Remaining Elements & Lifetime (Grouped Medians)\n",
    "# This handles the ~2,100 missing Expected Lifetime values\n",
    "sweep_cols = [\n",
    "    'Expected Lifetime (yrs.)', 'Period (minutes)', \n",
    "    'Inclination (degrees)', 'Eccentricity', \n",
    "    'Perigee (km)', 'Apogee (km)', 'Longitude of GEO (degrees)'\n",
    "]\n",
    "\n",
    "for col in sweep_cols:\n",
    "    if col in ucs_sats_messy.columns:\n",
    "        # We use Orbit Class to group because LEO/GEO physics vary wildly\n",
    "        orbit_medians = ucs_sats_messy.groupby('Class of Orbit')[col].transform('median')\n",
    "        ucs_sats_messy[col] = ucs_sats_messy[col].fillna(orbit_medians)\n",
    "\n",
    "# Global Fallback (Final Safety Net)\n",
    "ucs_sats_messy['Expected Lifetime (yrs.)'] = ucs_sats_messy['Expected Lifetime (yrs.)'].fillna(ucs_sats_messy['Expected Lifetime (yrs.)'].median())\n",
    "\n",
    "# FINAL COVERAGE VERIFICATION\n",
    "print(f\"\\n{'Column':<30} | {'Status'}\")\n",
    "print(\"-\" * 50)\n",
    "all_physics = sweep_cols + ['Launch Mass (kg.)', 'Dry Mass (kg.)', 'Power (watts)']\n",
    "for col in all_physics:\n",
    "    missing = ucs_sats_messy[col].isnull().sum()\n",
    "    print(f\"{col:<30} | {'‚úÖ COMPLETE' if missing == 0 else f'‚ùå {missing} MISSING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7fd4d",
   "metadata": {},
   "source": [
    "### **Stage 5: Schema Alignment (Renaming & Type Finalization)**\n",
    "\n",
    "**The Problem:** Raw UCS headers (e.g., `Name of Satellite, Alternate Names`) are too verbose for efficient coding and contain spaces/parentheses that can break certain SQL or Python operations.\n",
    "\n",
    "**The Solution:** Implement a global **Renaming Schema** to transition the dataset into a strict **snake_case** format. \n",
    "1. **Primary Key Alignment:** Rename `NORAD Number` to `norad_id` to match the SATCAT pipeline.\n",
    "2. **Physics Standardizing:** Shorten mass and power headers for programmatic speed.\n",
    "3. **Identifier Cleaning:** Finalize `COSPAR Number` as `cospar_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b44692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rename mapping\n",
    "column_mapping = {\n",
    "    'Name of Satellite, Alternate Names': 'satellite_name',\n",
    "    'Current Official Name of Satellite': 'official_name',\n",
    "    'Country/Org of UN Registry': 'un_registry',\n",
    "    'Country of Operator/Owner': 'country_operator',\n",
    "    'Operator/Owner': 'owner',\n",
    "    'Users': 'users',\n",
    "    'Purpose': 'purpose',\n",
    "    'Class of Orbit': 'orbit_class',\n",
    "    'Type of Orbit': 'orbit_type',\n",
    "    'Longitude of GEO (degrees)': 'geo_longitude',\n",
    "    'Perigee (km)': 'perigee_km',\n",
    "    'Apogee (km)': 'apogee_km',\n",
    "    'Eccentricity': 'eccentricity',\n",
    "    'Inclination (degrees)': 'inclination_degrees',\n",
    "    'Period (minutes)': 'period_minutes',\n",
    "    'Launch Mass (kg.)': 'launch_mass_kg',\n",
    "    'Date of Launch': 'launch_date',\n",
    "    'Expected Lifetime (yrs.)': 'lifetime_years',\n",
    "    'Contractor': 'contractor',\n",
    "    'Country of Contractor': 'contractor_country',\n",
    "    'Launch Site': 'launch_site',\n",
    "    'Launch Vehicle': 'launch_vehicle',\n",
    "    'COSPAR Number': 'cospar_id',\n",
    "    'NORAD Number': 'norad_id',\n",
    "    'Detailed Purpose': 'detailed_purpose',\n",
    "    'Dry Mass (kg.)': 'dry_mass_kg',\n",
    "    'Power (watts)': 'power_watts'\n",
    "}\n",
    "\n",
    "# Apply the Rename\n",
    "ucs_sats_messy.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Verification Check: Remaining messy headers\n",
    "messy_headers = [col for col in ucs_sats_messy.columns if ' ' in col or '(' in col]\n",
    "\n",
    "print(f\"--- Schema Finalization Report ---\")\n",
    "print(f\"Total Columns Standardized: {len(ucs_sats_messy.columns)}\")\n",
    "print(f\"Messy Headers Remaining:    {'None (Full Clean)' if not messy_headers else messy_headers}\")\n",
    "print(f\"Primary Merge Key:          { 'norad_id' in ucs_sats_messy.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760f362",
   "metadata": {},
   "source": [
    "### **Stage 6: Feature Engineering (Boolean Flags & Mission Standardization)**\n",
    "**The Problem:** The `users` column contains complex multi-stakeholder strings (e.g., \"Government/Commercial/Military\"), and the `purpose` column contains inconsistent terminology (e.g., \"Earth Science\" vs. \"Earth Observation\").\n",
    "\n",
    "**The Solution:**\n",
    "* **Boolean Flags:** Decompose the `users` column into binary indicators (`is_commercial`, `is_government`, `is_military`, `is_civil`) to enable precise sector-based querying.\n",
    "* **Mission Standardization:** Map diverse mission descriptions to a controlled vocabulary (e.g., Mapping \"Surveillance\" and \"Meteorological\" to **\"Earth Observation\"**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd542ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create User Boolean Flags (The \"Democratization\" Columns)\n",
    "# These flags allow queries like: \"Show me Civil satellites with NO Government involvement\"\n",
    "ucs_sats_messy['is_commercial'] = ucs_sats_messy['users'].str.contains('Commercial', case=False, na=False).astype(int)\n",
    "ucs_sats_messy['is_government'] = ucs_sats_messy['users'].str.contains('Government', case=False, na=False).astype(int)\n",
    "ucs_sats_messy['is_military'] = ucs_sats_messy['users'].str.contains('Military', case=False, na=False).astype(int)\n",
    "ucs_sats_messy['is_civil'] = ucs_sats_messy['users'].str.contains('Civil', case=False, na=False).astype(int)\n",
    "\n",
    "# Standardize Primary Purpose (The \"Mission\")\n",
    "def standardize_purpose(text):\n",
    "    if pd.isna(text) or text == 'Unknown':\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Take the first primary term if there are multiple (e.g. \"Comms/Nav\")\n",
    "    primary = text.split('/')[0].strip()\n",
    "    \n",
    "    mapping = {\n",
    "        'Earth Science': 'Earth Observation',\n",
    "        'Meteorological': 'Earth Observation',\n",
    "        'Surveillance': 'Earth Observation',\n",
    "        'Earth': 'Earth Observation',\n",
    "        'Earth/Space Observation': 'Earth Observation',\n",
    "        'Space Observation': 'Space Science',\n",
    "        'Technology Demonstration': 'Technology Development',\n",
    "        'Mission Extension Technology': 'Technology Development',\n",
    "        'Platform': 'Technology Development',\n",
    "        'Satellite Positioning': 'Navigation',\n",
    "        'Navigation': 'Navigation',\n",
    "        'Communications': 'Communications',\n",
    "        'Space Science': 'Space Science',\n",
    "        'Educational': 'Educational'\n",
    "    }\n",
    "    return mapping.get(primary, primary)\n",
    "\n",
    "ucs_sats_messy['primary_purpose'] = ucs_sats_messy['purpose'].apply(standardize_purpose)\n",
    "\n",
    "# Logical Reordering (Move primary_purpose next to purpose for easy checking)\n",
    "cols = list(ucs_sats_messy.columns)\n",
    "cols.remove('primary_purpose')\n",
    "target_index = cols.index('purpose')\n",
    "cols.insert(target_index + 1, 'primary_purpose')\n",
    "ucs_sats_messy = ucs_sats_messy[cols]\n",
    "\n",
    "print(\"\\n--- Mission Standardization Audit (Change Detection) ---\")\n",
    "columns_to_show = ['satellite_name', 'purpose', 'primary_purpose']\n",
    "diff_view = ucs_sats_messy[ucs_sats_messy['purpose'] != ucs_sats_messy['primary_purpose']][columns_to_show]\n",
    "\n",
    "if not diff_view.empty:\n",
    "    print(f\"Success: Standardized {len(diff_view)} complex mission labels into controlled vocabulary.\")\n",
    "    display(diff_view.head(10))\n",
    "else:\n",
    "    print(\"Verification: No complex labels found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d965f2",
   "metadata": {},
   "source": [
    "### **Stage 6.1: Orbit Class Standardization**\n",
    "**The Problem:** The `orbit_class` column contains synonymous but inconsistent labels (e.g., \"Low Earth Orbit\" vs \"LEO\"). \n",
    "\n",
    "**The Solution:** Implement a mapping dictionary to consolidate all orbital regimes into four standardized categories: **LEO, MEO, GEO,** and **Elliptical**. This ensures compatibility with the SATCAT classification logic used in the next phase of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Orbit Class (The Region)\n",
    "orbit_class_map = {\n",
    "    'LEO': 'LEO',\n",
    "    'GEO': 'GEO',\n",
    "    'MEO': 'MEO',\n",
    "    'ELLIPTICAL': 'Elliptical',\n",
    "    'Elliptical': 'Elliptical'\n",
    "}\n",
    "\n",
    "# 2. Standardize Orbit Type (The Geometry)\n",
    "# We'll group these into Polar, Non-Polar, and Eccentric\n",
    "orbit_type_map = {\n",
    "    'Non-Polar Inclined': 'Inclined',\n",
    "    'Sun-Synchronous': 'Polar',\n",
    "    'Polar': 'Polar',\n",
    "    'Equatorial': 'Equatorial',\n",
    "    'Molniya': 'Eccentric',\n",
    "    'Deep Highly Eccentric': 'Eccentric',\n",
    "    'Elliptical': 'Eccentric',\n",
    "    'Sun-Synchronous near polar': 'Polar',\n",
    "    'Cislunar': 'Eccentric',\n",
    "    'Retrograde': 'Inclined'\n",
    "}\n",
    "\n",
    "# Apply mappings with .str.strip() to catch any hidden spaces\n",
    "ucs_sats_messy['orbit_class'] = ucs_sats_messy['orbit_class'].str.strip().map(orbit_class_map).fillna('Unknown')\n",
    "ucs_sats_messy['orbit_type'] = ucs_sats_messy['orbit_type'].str.strip().map(orbit_type_map).fillna('Other/Misc')\n",
    "\n",
    "print(\"--- Final Distribution Post-Fix ---\")\n",
    "print(ucs_sats_messy['orbit_class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebbeb5",
   "metadata": {},
   "source": [
    "### **Stage 7: Pipeline Serialization & Executive Summary**\n",
    "**Objective:** Finalize the active population for export.\n",
    "\n",
    "We have successfully addressed two critical data gaps:\n",
    "1. **The \"Mass Transparency Gap\":** Addressed via the **ISS Exception**, **Grouped Median Imputation**, and **Physics-Informed Ratios**, making this the high-fidelity mass reference for collision models.\n",
    "2. **The \"Metadata Consistency Gap\":** Addressed via **Boolean Sector Flags** (e.g., `is_military`) and **Mission Standardization**, transforming raw text into machine-readable categories.\n",
    "\n",
    "**Outcome:** This dataset is now normalized, validated, and ready for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/clean/ucs_cleaned.csv'\n",
    "\n",
    "# Calculate Sector Metrics\n",
    "total_rows = len(ucs_sats_messy)\n",
    "comm_count = ucs_sats_messy['is_commercial'].sum()\n",
    "mil_count  = ucs_sats_messy['is_military'].sum()\n",
    "gov_count  = ucs_sats_messy['is_government'].sum()\n",
    "civ_count  = ucs_sats_messy['is_civil'].sum()\n",
    "\n",
    "# Congestion Metrics (The Polar Alert)\n",
    "# Focusing on LEO for congestion analysis\n",
    "leo_mask = ucs_sats_messy['orbit_class'] == 'LEO'\n",
    "polar_leo_count = ucs_sats_messy[leo_mask & (ucs_sats_messy['orbit_type'] == 'Polar')].shape[0]\n",
    "polar_share = (polar_leo_count / ucs_sats_messy[leo_mask].shape[0]) if total_rows > 0 else 0\n",
    "\n",
    "# Calculate Mission Metrics\n",
    "top_missions = ucs_sats_messy['primary_purpose'].value_counts().head(3)\n",
    "m1_n, m1_c = top_missions.index[0], top_missions.values[0]\n",
    "m2_n, m2_c = top_missions.index[1], top_missions.values[1]\n",
    "m3_n, m3_c = top_missions.index[2], top_missions.values[2]\n",
    "\n",
    "# Comprehensive Data Quality Audit\n",
    "# Including geo_longitude to ensure 100% density across the physics suite\n",
    "physics_features = [\n",
    "    'launch_mass_kg', 'dry_mass_kg', 'power_watts', \n",
    "    'period_minutes', 'lifetime_years', 'perigee_km', \n",
    "    'apogee_km', 'eccentricity', 'inclination_degrees',\n",
    "    'geo_longitude'\n",
    "]\n",
    "\n",
    "# Generate the report\n",
    "report = f\"\"\"\n",
    "### **UCS Pipeline Completion Report: Platinum Edition**\n",
    "**Total Active Registry:** {total_rows:,} satellites\n",
    "\n",
    "#### **Sector Composition**\n",
    "| Sector | Count | Share |\n",
    "| :--- | :--- | :--- |\n",
    "| **Commercial** | {comm_count:,} | {comm_count/total_rows:.1%} |\n",
    "| **Military** | {mil_count:,} | {mil_count/total_rows:.1%} |\n",
    "| **Government** | {gov_count:,} | {gov_count/total_rows:.1%} |\n",
    "| **Civil** | {civ_count:,} | {civ_count/total_rows:.1%} |\n",
    "| **Polar Congestion (LEO)** | {polar_leo_count:,} | {polar_share:.1%} of LEO ‚ö†Ô∏è |\n",
    "\n",
    "#### **Primary Mission Breakdown**\n",
    "| Top Mission | Count | Share |\n",
    "| :--- | :--- | :--- |\n",
    "| **1. {m1_n}** | {m1_c:,} | {m1_c/total_rows:.1%} |\n",
    "| **2. {m2_n}** | {m2_c:,} | {m2_c/total_rows:.1%} |\n",
    "| **3. {m3_n}** | {m3_c:,} | {m3_c/total_rows:.1%} |\n",
    "\n",
    "#### **Data Quality & Imputation Success**\n",
    "| Feature | Completeness | Method | Status |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "\"\"\"\n",
    "\n",
    "for feature in physics_features:\n",
    "    coverage = ucs_sats_messy[feature].notna().mean()\n",
    "    method = \"Calculated/Imputed\" if coverage == 1.0 else \"Incomplete\"\n",
    "    report += f\"| **{feature.replace('_', ' ').title()}** | **{coverage:.1%}** | {method} | ‚úÖ SUCCESS |\\n\"\n",
    "\n",
    "report += f\"\\nüíæ **File Saved:** `{output_path}`\"\n",
    "\n",
    "display(Markdown(report))\n",
    "ucs_sats_messy.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a559c4",
   "metadata": {},
   "source": [
    "## **Registry Cleanup Complete**\n",
    "\n",
    "**Summary of Operations:**\n",
    "- **Normalized** 7,500+ active satellite entries into a standardized schema.\n",
    "- **Reconstructed** missing physical data using a multi-tiered imputation engine (Keplerian physics, mass-ratios, and mission-based medians).\n",
    "- **Engineered** Boolean flags for sector analysis and standardized orbital regimes.\n",
    "\n",
    "**Next Notebook:** `satcat_cleanup.ipynb`\n",
    "- Merge with the CelesTrak SATCAT to incorporate debris, rocket bodies, and radar cross-sections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
