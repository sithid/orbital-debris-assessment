{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bebdea8",
   "metadata": {},
   "source": [
    "### **SATCAT Data Pipeline: Global Registry Standardization**\n",
    "\n",
    "**Dataset:** CelesTrak Satellite Catalog (SATCAT)  \n",
    "**Objective:** Transform raw orbital tracking data into a physics-ready, \"Gold Standard\" global registry.\n",
    "\n",
    "### **The Engineering Challenge**\n",
    "The raw SATCAT is the premier source for orbital tracking (location) but presents a significant **Physics Transparency Gap**. While it identifies ~60,000 objects, nearly **82.9%** lack critical mass data, and many fields contain non-numeric placeholders or uncalibrated Radar Cross Section (RCS) values.\n",
    "\n",
    "1.  **Ingestion & Schema Alignment:** Normalize headers to strict `snake_case` and implement `in_orbit` logic.\n",
    "2.  **Physics Sanitization:** Neutralize `0.0` placeholders and enforce numeric type-safety.\n",
    "3.  **Keplerian Reconstruction:** Mathematically derive missing orbital periods using Keplerâ€™s Third Law.\n",
    "4.  **Tiered Mass Imputation:** Apply ESA-standard proxies for Debris and Rocket Bodies to provide a kinetic baseline.\n",
    "5.  **Categorical & Geopolitical Hardening:** Normalize object types and owner codes for seamless relational integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feecfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1128ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff8bc44",
   "metadata": {},
   "source": [
    "### **Stage 1: Ingestion & Schema Alignment**\n",
    "**The Problem:** The raw SATCAT headers use legacy uppercase formatting (e.g., `NORAD_CAT_ID`), which is inconsistent with our UCS snake_case convention. Furthermore, a \"Gold Standard\" dataset must preserve all original metadata to ensure no information is lost during the standardization process.\n",
    "\n",
    "**The Solution:** * **Global Renaming:** We map critical physical and relational headers to `snake_case` to match the UCS pipeline's \"DNA\".\n",
    "* **Feature Preservation:** We retain 100% of the original columns, only renaming the essential ones for programmatic efficiency.\n",
    "* **In-Orbit Logic:** We introduce the `in_orbit` booleanâ€”a primary feature that separates active kinetic threats from historical decay records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_registry = pd.read_csv('../data/original/satcat.csv')\n",
    "\n",
    "rename_map = {\n",
    "    'OBJECT_NAME': 'object_name',\n",
    "    'OBJECT_ID': 'cospar_id',            # Perfect Match with UCS\n",
    "    'NORAD_CAT_ID': 'norad_id',          # Perfect Match with UCS\n",
    "    'OBJECT_TYPE': 'object_type',        # Refined in Stage 4\n",
    "    'OPS_STATUS_CODE': 'ops_status',   \n",
    "    'OWNER': 'owner_code',               # To be enriched by UCS 'owner'\n",
    "    'LAUNCH_DATE': 'launch_date',        # Standardized to datetime\n",
    "    'LAUNCH_SITE': 'launch_site',        # Matches UCS\n",
    "    'DECAY_DATE': 'decay_date',\n",
    "    'PERIOD': 'period_minutes',          # Standardized Physics\n",
    "    'INCLINATION': 'inclination_degrees',# Standardized Physics\n",
    "    'APOGEE': 'apogee_km',               # Standardized Physics\n",
    "    'PERIGEE': 'perigee_km',             # Standardized Physics\n",
    "    'RCS': 'rcs',                        # Core for Kinetic Modeling\n",
    "    'DATA_STATUS_CODE': 'data_status', \n",
    "    'ORBIT_CENTER': 'orbit_center',    \n",
    "    'ORBIT_TYPE': 'orbit_type_code'      # Changed to prevent merge collision\n",
    "}\n",
    "\n",
    "registry = raw_registry.rename(columns=rename_map).copy()\n",
    "\n",
    "registry['in_orbit'] = registry['decay_date'].isnull().astype(int)\n",
    "\n",
    "print(f\"--- Stage 1 Audit ---\")\n",
    "print(f\"Total Columns Retained: {len(registry.columns)}\")\n",
    "print(f\"Total Records:         {len(registry):,}\")\n",
    "print(f\"In-Orbit Boolean:      Added (Density: {registry['in_orbit'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6411d",
   "metadata": {},
   "source": [
    "### **Stage 1.1: Strategic Ghost Column Audit**\n",
    "**The Problem:** Raw CSV exports often contain \"Ghost Columns\" â€” unpopulated placeholders created by formatting artifacts or trailing delimiters in the original database. These columns inflate memory usage and create \"Wide Data\" noise without adding informational value.\n",
    "\n",
    "**The Solution:** We implement a **Dynamic Artifact Filter** to identify and purge any columns matching the `Unnamed` pattern or those containing 100% null values. This ensures the dataset remains lean and focused on valid orbital attributes while preserving 100% of the legitimate SATCAT metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter off unwanted columns dynamically to account for version updates\n",
    "unnamed_columns = [col for col in registry.columns if 'Unnamed' in col]\n",
    "null_columns = [col for col in registry.columns if registry[col].isnull().all()]\n",
    "ghost_columns = list(set(unnamed_columns + null_columns))\n",
    "\n",
    "print(f\"--- Ghost Column Audit ---\")\n",
    "if ghost_columns:\n",
    "    print(f\"Found {len(ghost_columns)} artifact columns: {ghost_columns}\")\n",
    "    registry.drop(columns=ghost_columns, inplace=True)\n",
    "    print(f\"âœ… SUCCESS: Artifacts purged. Remaining columns: {len(registry.columns)}\")\n",
    "else:\n",
    "    print(\"âœ… CLEAN: No ghost columns or 100% null artifacts detected.\")\n",
    "\n",
    "essential_keys = ['norad_id', 'object_name', 'in_orbit', 'period_minutes', 'perigee_km', 'apogee_km', 'inclination_degrees', 'rcs']\n",
    "integrity_check = all(key in registry.columns for key in essential_keys)\n",
    "print(f\"Relational Integrity Check: {'PASSED' if integrity_check else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207e9a9",
   "metadata": {},
   "source": [
    "### **Stage 1.2: Pre-Sanitization Health Audit**\n",
    "**The Problem:** Before enforcing physics standardization, we must quantify the scale of the **Transparency Gap** in the raw registry. Treating `0.0` or string artifacts as valid data during initial EDA would lead to a \"Ghost Population\" that appears to have no mass or motion, skewing our baseline risk assessments.\n",
    "\n",
    "**The Solution:** We execute a technical audit to identify \"Non-Physical\" values across our five core attributes. This report tracks:\n",
    "* **String Artifacts:** Non-numeric entries that force columns into `object` types.\n",
    "* **Placeholder Zeros:** Valid numeric `0.0` entries that actually represent missing data in the SATCAT.\n",
    "* **Density Baseline:** The true percentage of \"Physics-Ready\" data available in the raw source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca959f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core kinetic and geometric attributes\n",
    "physics_cols = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'rcs']\n",
    "\n",
    "print(f\"{'--- RAW DATA HEALTH AUDIT ---':^55}\")\n",
    "print(f\"{'Column':<20} | {'Non-Numeric':<12} | {'Zeros':<8} | {'Health %'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "total_records = len(registry)\n",
    "\n",
    "for col in physics_cols:\n",
    "    if col in registry.columns:\n",
    "        # 1. Count Non-Numeric (Strings/NaNs)\n",
    "        # We try to convert to numeric safely to find what is currently a string\n",
    "        numeric_series = pd.to_numeric(registry[col], errors='coerce')\n",
    "        non_numeric = registry[col].isna().sum() + (registry[col].apply(lambda x: isinstance(x, str))).sum()\n",
    "        \n",
    "        # 2. Count Placeholder Zeros (Numeric 0.0)\n",
    "        # Note: We check the numeric version for zeros\n",
    "        zeros = (numeric_series == 0).sum()\n",
    "        \n",
    "        # 3. Calculate \"Physics-Ready\" Density\n",
    "        # Valid = Not NaN AND Not Zero\n",
    "        valid_count = total_records - (non_numeric + zeros)\n",
    "        health_pct = (valid_count / total_records) * 100\n",
    "        \n",
    "        print(f\"{col:<20} | {non_numeric:>12,} | {zeros:>8,} | {health_pct:>7.1f}%\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "print(f\"Total Registry Records: {total_records:,}\")\n",
    "print(\"Note: 'Health %' represents records that are both numeric and non-zero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395c89e",
   "metadata": {},
   "source": [
    "### **Stage 2: Universal Numeric & Identifier Sanitization**\n",
    "**The Problem:** High-fidelity orbital modeling requires strict numeric types. However, fields like `rcs`, `period_minutes`, and `perigee_km` often contain `0.0` as a placeholder for \"Unknown\" data. Furthermore, primary identifiers like `norad_id` and `cospar_id` can contain decimal artifacts or hidden whitespace that prevent clean merging.\n",
    "\n",
    "**The Solution:**\n",
    "* **Numeric Coercion:** We apply `pd.to_numeric` across all core physics columns to ensure a stable `float64` foundation.\n",
    "* **Placeholder Neutralization:** We convert `0.0` values to `NaN` to ensure missing data is handled correctly by statistical functions.\n",
    "* **ID Normalization:** We force `norad_id` to a clean integer-string and apply a deep string-scrub to `cospar_id` to ensure 1:1 join-readiness with the UCS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffcb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded lists for universal sanitization\n",
    "physics_cols = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'rcs']\n",
    "id_numeric_cols = ['norad_id']\n",
    "id_string_cols = ['cospar_id']\n",
    "\n",
    "print(f\"Sanitizing {len(physics_cols) + len(id_numeric_cols) + len(id_string_cols)} attributes...\")\n",
    "\n",
    "# 1. Standardize Numeric Identifiers (UCS Stage 3.3 Logic)\n",
    "for col in id_numeric_cols:\n",
    "    if col in registry.columns:\n",
    "        # Strip decimal artifacts (e.g., 25544.0 -> 25544)\n",
    "        registry[col] = pd.to_numeric(registry[col], errors='coerce')\n",
    "        registry = registry.dropna(subset=[col])\n",
    "        registry[col] = registry[col].astype(int).astype(str)\n",
    "\n",
    "# 2. Standardize String Identifiers\n",
    "for col in id_string_cols:\n",
    "    if col in registry.columns:\n",
    "        # Strip whitespace and normalize case to prevent \"Invisible Bug\" merge failures\n",
    "        registry[col] = registry[col].astype(str).str.strip().str.upper()\n",
    "        # Neutralize 'NAN' strings\n",
    "        registry[col] = registry[col].replace('NAN', np.nan)\n",
    "\n",
    "# 3. Sanitization Loop for Physics (UCS Stage 3.2 & 4.2 Logic)\n",
    "for col in physics_cols:\n",
    "    if col in registry.columns:\n",
    "        # Force to numeric foundation\n",
    "        registry[col] = pd.to_numeric(registry[col], errors='coerce')\n",
    "        \n",
    "        # Neutralize 0.0 placeholders representing 'Missing' data\n",
    "        registry[col] = registry[col].replace(0, np.nan)\n",
    "        \n",
    "        # Enforce Physical Constraints: Geometry cannot be negative\n",
    "        if col != 'rcs':\n",
    "            registry.loc[registry[col] < 0, col] = 0\n",
    "\n",
    "# Verification Diagnostic\n",
    "print(\"\\n--- Final Sanitization Health Check ---\")\n",
    "for col in physics_cols + id_numeric_cols + id_string_cols:\n",
    "    null_count = registry[col].isnull().sum()\n",
    "    dtype = registry[col].dtype\n",
    "    print(f\"{col:<20} | Nulls: {null_count:>6,} | Type: {dtype}\")\n",
    "\n",
    "print(\"\\nâœ… Stage 2 Complete: Numeric and Identifier integrity enforced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fb1a9",
   "metadata": {},
   "source": [
    "### **Stage 3: Keplerian Reconstruction (The Density Engine)**\n",
    "**The Problem:** Despite being a tracking catalog, many entries possess Perigee and Apogee data but are missing a recorded `period_minutes`. To achieve 100% density for our kinetic models, we cannot rely on incomplete records or \"ghost\" orbits that appear to have no motion.\n",
    "\n",
    "**The Solution:** We implement **Keplerâ€™s Third Law**. By treating Earth's gravitational constant ($\\mu$) and radius as constants, we can mathematically derive the missing periods from the existing orbital geometry. This ensures every object flagged as `in_orbit` is physics-ready for downstream kinetic energy calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earth Constants for Orbital Mechanics\n",
    "earth_radius = 6378.137\n",
    "mu = 398600.4418 # km^3/s^2 (Earth's gravitational parameter)\n",
    "\n",
    "def calculate_kepler_period(row):\n",
    "    \"\"\"\n",
    "    Derives orbital period from altitudes if the period is missing.\n",
    "    Matches the derivation logic used in ucs_cleanup Stage 4.2.\n",
    "    \"\"\"\n",
    "    # Only derive if Period is missing but we have altitudes\n",
    "    if pd.isna(row['period_minutes']) and not pd.isna(row['perigee_km']) and not pd.isna(row['apogee_km']):\n",
    "        # a = semi-major axis (Earth Radius + Average Altitude)\n",
    "        a = earth_radius + ((row['perigee_km'] + row['apogee_km']) / 2)\n",
    "        # T = 2 * pi * sqrt(a^3 / mu)\n",
    "        period_seconds = 2 * np.pi * np.sqrt(a**3 / mu)\n",
    "        return period_seconds / 60\n",
    "    return row['period_minutes']\n",
    "\n",
    "print(\"Executing Keplerian Reconstruction...\")\n",
    "registry['period_minutes'] = registry.apply(calculate_kepler_period, axis=1)\n",
    "\n",
    "# Diagnostic Audit of the In-Orbit Population\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "missing_p = registry[in_orbit_mask]['period_minutes'].isnull().sum()\n",
    "\n",
    "print(f\"\\n--- Keplerian Audit ---\")\n",
    "print(f\"Remaining Missing Periods (In-Orbit): {missing_p}\")\n",
    "print(f\"Period Density (In-Orbit):           {registry[in_orbit_mask]['period_minutes'].notna().mean():.1%}\")\n",
    "\n",
    "if missing_p == 0:\n",
    "    print(\"\\nðŸš€ SUCCESS: 100% Period density achieved for the in-orbit population.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92afd1",
   "metadata": {},
   "source": [
    "### **Stage 3.1: Orbital Classification & Final Period Imputation**\n",
    "**The Problem:** Our Keplerian reconstruction achieved 98.1% density, but 615 objects remain \"Physics-Blind\" because they lack both a recorded period and altitude data. In the UCS pipeline, we addressed similar gaps by leveraging **Grouped Median Imputation**.\n",
    "\n",
    "**The Solution:** * **Regime Classification:** We implement a `classify_orbit` function to group all objects into **LEO, MEO, GEO,** or **High Elliptical** based on their orbital period.\n",
    "* **Peer-Group Imputation:** For the final 615 objects, we fill the missing `period_minutes` using the median value of their respective orbital class. This mirrors the Stage 4.2 logic from the UCS cleanup and ensures 100% density for the in-orbit population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54566fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_orbit(period):\n",
    "    \"\"\"\n",
    "    Translates orbital period into standardized regimes.\n",
    "    Logic based on SATCAT engineering standards.\n",
    "    \"\"\"\n",
    "    if pd.isnull(period) or period <= 0:\n",
    "        return 'UNKNOWN'\n",
    "    elif period < 128:\n",
    "        return 'LEO'\n",
    "    elif 1400 <= period <= 1460:\n",
    "        return 'GEO'\n",
    "    elif 128 <= period < 1400:\n",
    "        return 'MEO'\n",
    "    else:\n",
    "        return 'Elliptical'\n",
    "\n",
    "# 1. Apply initial classification\n",
    "registry['orbit_class'] = registry['period_minutes'].apply(classify_orbit)\n",
    "\n",
    "# 2. Impute Remaining Periods (UCS Stage 4.2 Logic)\n",
    "# We use the median of the orbit_class to fill the final gaps\n",
    "print(f\"Imputing final {registry[registry['in_orbit'] == 1]['period_minutes'].isnull().sum()} periods...\")\n",
    "\n",
    "# Calculate medians by orbit class\n",
    "orbit_medians = registry.groupby('orbit_class')['period_minutes'].transform('median')\n",
    "registry['period_minutes'] = registry['period_minutes'].fillna(orbit_medians)\n",
    "\n",
    "# 3. Global Safety Net (In case orbit_class was 'UNKNOWN')\n",
    "global_median = registry['period_minutes'].median()\n",
    "registry['period_minutes'] = registry['period_minutes'].fillna(global_median)\n",
    "\n",
    "# 4. Final Physics Audit\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "missing_final = registry[in_orbit_mask]['period_minutes'].isnull().sum()\n",
    "\n",
    "print(f\"\\n--- Final Physics Density Audit ---\")\n",
    "print(f\"Remaining Missing Periods (In-Orbit): {missing_final}\")\n",
    "print(f\"Final Period Density:                {registry[in_orbit_mask]['period_minutes'].notna().mean():.1%}\")\n",
    "\n",
    "if missing_final == 0:\n",
    "    print(\"\\nðŸš€ SUCCESS: 100% Physics density achieved via Grouped Median Imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3458c58",
   "metadata": {},
   "source": [
    "### **Stage 3.2: Final Geometric Sweep**\n",
    "**The Problem:** While our Period density is now at 100%, the underlying geometric attributesâ€”`inclination_degrees`, `apogee_km`, and `perigee_km`â€”still contain the `NaN` values we neutralized in Stage 2. A \"Gold Standard\" dataset requires 100% density across the entire physical profile to support precise kinetic modeling.\n",
    "\n",
    "**The Solution:** Perform a final median sweep across the remaining geometric features. We leverage the `orbit_class` we just engineered to fill these gaps with regime-specific medians, ensuring that an \"Unknown LEO\" object receives the physical characteristics typical of its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f761b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_cols = ['inclination_degrees', 'apogee_km', 'perigee_km']\n",
    "\n",
    "print(\"Executing Final Geometric Sweep...\")\n",
    "\n",
    "for col in sweep_cols:\n",
    "    if col in registry.columns:\n",
    "        # 1. Primary Fill: Grouped by the Orbit Class we just created\n",
    "        regime_medians = registry.groupby('orbit_class')[col].transform('median')\n",
    "        registry[col] = registry[col].fillna(regime_medians)\n",
    "        \n",
    "        # 2. Safety Fill: Global Median (for any 'UNKNOWN' regimes)\n",
    "        registry[col] = registry[col].fillna(registry[col].median())\n",
    "\n",
    "# Final Physics Quality Gate\n",
    "print(f\"\\n{'--- FINAL GEOMETRY AUDIT ---':^45}\")\n",
    "print(f\"{'Feature':<25} | {'Completeness'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for col in ['period_minutes'] + sweep_cols:\n",
    "    coverage = registry[registry['in_orbit'] == 1][col].notna().mean()\n",
    "    print(f\"{col:<25} | {coverage:>12.1%}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(\"ðŸš€ PASS: 100% Geometric density achieved for the in-orbit population.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3100bdd",
   "metadata": {},
   "source": [
    "### **Stage 3.3: Integrity Polish & Eccentricity Derivation**\n",
    "**The Problem:** While our altitude and period density are at 100%, the SATCAT is missing an explicit **`eccentricity`** field, which is a core requirement for the kinetic models used in the UCS pipeline. Additionally, **`geo_longitude`** must be neutralized to ensure it doesn't contain string artifacts.\n",
    "\n",
    "**The Solution:** \n",
    "* **Mathematical Derivation:** We derive eccentricity using the formula $e = (r_a - r_p) / (r_a + r_p)$, where $r$ is the distance from the Earth's center. \n",
    "* **Schema Alignment:** We add these features to our final \"Gold Standard\" sweep to ensure 100% parity with the UCS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc92436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive Eccentricity\n",
    "# Formula: e = (Apogee - Perigee) / (Apogee + Perigee + 2*Earth_Radius)\n",
    "earth_radius = 6378.137\n",
    "\n",
    "def derive_eccentricity(row):\n",
    "    ra = row['apogee_km'] + earth_radius\n",
    "    rp = row['perigee_km'] + earth_radius\n",
    "    return (ra - rp) / (ra + rp)\n",
    "\n",
    "print(\"Deriving orbital eccentricity...\")\n",
    "registry['eccentricity'] = registry.apply(derive_eccentricity, axis=1)\n",
    "\n",
    "# 2. Initialize geo_longitude if it doesn't exist (to match UCS schema)\n",
    "if 'geo_longitude' not in registry.columns:\n",
    "    registry['geo_longitude'] = np.nan\n",
    "\n",
    "# 3. Final Sweep for the \"Missing Two\"\n",
    "final_sweep = ['eccentricity', 'geo_longitude']\n",
    "\n",
    "for col in final_sweep:\n",
    "    # Grouped Median Fill\n",
    "    regime_medians = registry.groupby('orbit_class')[col].transform('median')\n",
    "    registry[col] = registry[col].fillna(regime_medians)\n",
    "    \n",
    "    # Global Safety Net\n",
    "    # GEO longitude defaults to 0 for non-GEO\n",
    "    registry[col] = registry[col].fillna(0.0)\n",
    "\n",
    "print(f\"\\n{'--- COMPLETE GEOMETRIC AUDIT ---':^45}\")\n",
    "print(f\"{'Feature':<25} | {'Completeness'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "all_geo = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'eccentricity', 'geo_longitude']\n",
    "for col in all_geo:\n",
    "    coverage = registry[registry['in_orbit'] == 1][col].notna().mean()\n",
    "    print(f\"{col:<25} | {coverage:>12.1%}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(\"ðŸš€ PASS: 100% Parity with UCS geometric schema achieved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57369c54",
   "metadata": {},
   "source": [
    "### **Stage 4: Categorical Hardening & String Scrubbing**\n",
    "**The Problem:** The raw SATCAT utilizes abbreviated codes (e.g., `PAY`, `R/B`) and inconsistent string formatting. Mixed-case entries and trailing whitespacesâ€”\"Invisible Bugs\"â€”can cause silent failures during categorical grouping or when merging with the UCS dataset later in the pipeline.\n",
    "\n",
    "**The Solution:**\n",
    "* **Object Mapping:** We translate raw codes into a controlled vocabulary (`PAYLOAD`, `ROCKET BODY`, `DEBRIS`) to ensure clarity.\n",
    "* **Geopolitical Normalization:** We enforce a strict uppercase and `strip()` operation on `owner_code` and `launch_site` to ensure unique labels for geopolitical analysis.\n",
    "* **Deep Scrub:** We iterate through all text-based columns to neutralize whitespace artifacts and ensure the registry meets our \"Gold Standard\" for data cleanliness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Object Types to human-readable vocabulary\n",
    "type_map = {\n",
    "    'PAY': 'PAYLOAD', \n",
    "    'R/B': 'ROCKET BODY', \n",
    "    'DEB': 'DEBRIS',\n",
    "    'UNK': 'UNKNOWN'\n",
    "}\n",
    "\n",
    "print(\"Standardizing object classifications...\")\n",
    "registry['object_type'] = registry['object_type'].str.strip().str.upper().map(type_map).fillna('UNKNOWN')\n",
    "\n",
    "# Global String Scrubbing\n",
    "text_cols = registry.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Executing Deep Scrub on {len(text_cols)} text columns...\")\n",
    "for col in text_cols:\n",
    "    registry[col] = registry[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3. Neutralize 'NAN' strings back to proper np.nan\n",
    "registry = registry.replace('NAN', np.nan)\n",
    "\n",
    "# 4. Final Categorical Audit\n",
    "print(\"\\n--- Categorical Distribution ---\")\n",
    "print(registry['object_type'].value_counts())\n",
    "\n",
    "print(f\"\\nâœ… Stage 4 Complete: {len(text_cols)} columns standardized and scrubbed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4685b8",
   "metadata": {},
   "source": [
    "### **Stage 4.1: Operational Status Hardening**\n",
    "**The Problem:** Raw tracking data utilizes legacy shorthand for satellite health (e.g., `+` for operational, `-` for non-operational). These codes are insufficient for high-level risk reporting or geopolitical audits.\n",
    "\n",
    "**The Solution:** We map the single-character status codes to standardized, human-readable labels. This ensures that the registry's operational context is immediately accessible and ready for \"Zombie\" identification in the next phase of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map legacy single-character status codes to human-readable labels\n",
    "# Source: CelesTrak SATCAT Legend\n",
    "status_map = {\n",
    "    '+': 'OPERATIONAL',\n",
    "    '-': 'NON-OPERATIONAL',\n",
    "    'P': 'PARTIAL',\n",
    "    'B': 'BACKUP/STANDBY',\n",
    "    'S': 'STANDBY',\n",
    "    'X': 'EXTENDED MISSION',\n",
    "    'D': 'DECAYED'\n",
    "}\n",
    "\n",
    "print(\"Hardening operational status codes...\")\n",
    "\n",
    "# Apply mapping and handle missing values\n",
    "registry['ops_status'] = registry['ops_status'].map(status_map).fillna('UNKNOWN')\n",
    "\n",
    "print(\"\\n--- Operational Status Distribution ---\")\n",
    "print(registry['ops_status'].value_counts())\n",
    "\n",
    "print(\"\\nâœ… Stage 4.1 Complete: Legacy status codes standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ccd1e",
   "metadata": {},
   "source": [
    "### **Stage 4.2: High-Fidelity Data Enrichment (UCS Integration)**\n",
    "**The Problem:** The raw SATCAT contains no physical mass data, creating a 100% Transparency Gap. Furthermore, standard `pd.read_csv` operations often infer ID columns as integers, which causes `ValueErrors` when merging against our sanitized string-based identifiers.\n",
    "\n",
    "**The Solution:** We load the `ucs_cleaned.csv` while explicitly forcing the `norad_id` to a string type. We then perform a targeted \"Left Join\" on the registry. This reduces our mass gap from 100% down to the ~82.8% specifically composed of debris and rocket bodies, ensuring we use the best available data for active assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaee9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucs_path = '../data/clean/ucs_cleaned.csv'\n",
    "\n",
    "# We use dtype={'norad_id': str} to prevent pandas from inferring it as an integer\n",
    "ucs_clean = pd.read_csv(ucs_path, dtype={'norad_id': str})\n",
    "\n",
    "print(f\"Loading UCS reference data... Found {len(ucs_clean):,} high-fidelity records.\")\n",
    "\n",
    "# Targeted Enrichment Merge\n",
    "registry['norad_id'] = registry['norad_id'].astype(str)\n",
    "\n",
    "registry = registry.merge(\n",
    "    ucs_clean[['norad_id', 'launch_mass_kg']], \n",
    "    on='norad_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Transparency Audit (The \"Real\" Gap Discovery)\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "total_in_orbit = registry[in_orbit_mask].shape[0]\n",
    "\n",
    "# Check how many we successfully enriched from UCS\n",
    "known_mass_count = registry[in_orbit_mask]['launch_mass_kg'].notna().sum()\n",
    "gap_count = total_in_orbit - known_mass_count\n",
    "gap_percent = (gap_count / total_in_orbit) * 100\n",
    "\n",
    "print(f\"\\n{'--- ENRICHED MASS TRANSPARENCY AUDIT ---':^50}\")\n",
    "print(f\"Total In-Orbit Objects:     {total_in_orbit:,}\")\n",
    "print(f\"UCS-Enriched (High-Fi):     {known_mass_count:,} ({100-gap_percent:.1f}%)\")\n",
    "print(f\"Remaining 'Invisible' Gap:  {gap_count:,} ({gap_percent:.1f}%)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Identify the types of objects remaining in the gap\n",
    "gap_breakdown = registry[in_orbit_mask & registry['launch_mass_kg'].isna()]['object_type'].value_counts()\n",
    "print(\"\\n--- Distribution of Remaining Gap (By Object Type) ---\")\n",
    "print(gap_breakdown)\n",
    "\n",
    "print(f\"\\nâœ… Enrichment Complete. Remaining {gap_percent:.1f}% gap identified for Stage 5 proxies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60ad81",
   "metadata": {},
   "source": [
    "### **Stage 5: Tiered Mass Imputation (The Proxy Engine)**\n",
    "**The Problem:** Even after UCS enrichment, a ~82.8% gap remains, primarily composed of Debris and Rocket Bodies. To complete our kinetic model, these objects require a physical baseline.\n",
    "\n",
    "**The Solution:** We initialize `proxy_mass_kg`. We preserve the high-fidelity UCS data where it exists, but fill the remaining `NaN` values using conservative averages from the **European Space Agency (ESA) Space Debris Report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89442bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize proxy mass from any existing RCS-derived or reported mass data\n",
    "# If 'launch_mass_kg' doesn't exist yet in the standalone, we initialize it\n",
    "if 'launch_mass_kg' not in registry.columns:\n",
    "    registry['launch_mass_kg'] = np.nan\n",
    "\n",
    "registry['proxy_mass_kg'] = registry['launch_mass_kg']\n",
    "\n",
    "# Define categorical averages based on ESA Space Debris Environment Reports\n",
    "# These provide a conservative baseline for kinetic energy modeling\n",
    "mass_proxies = {\n",
    "    'ROCKET BODY': 2000.0,\n",
    "    'PAYLOAD': 1000.0,\n",
    "    'DEBRIS': 0.1,\n",
    "    'UNKNOWN': 0.1\n",
    "}\n",
    "\n",
    "print(\"Applying Tiered Mass Imputation...\")\n",
    "\n",
    "for category, mass_val in mass_proxies.items():\n",
    "    # Only fill where proxy_mass is currently missing/NaN\n",
    "    mask = (registry['object_type'] == category) & (registry['proxy_mass_kg'].isna())\n",
    "    registry.loc[mask, 'proxy_mass_kg'] = mass_val\n",
    "\n",
    "proxy_density = registry[registry['in_orbit'] == 1]['proxy_mass_kg'].notna().mean()\n",
    "\n",
    "print(f\"\\n--- Mass Transparency Audit ---\")\n",
    "print(f\"Final Proxy Mass Density (In-Orbit): {proxy_density:.1%}\")\n",
    "\n",
    "if proxy_density == 1.0:\n",
    "    print(\"\\nðŸš€ SUCCESS: 100% Kinetic density achieved. Registry is physics-ready.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
