{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bebdea8",
   "metadata": {},
   "source": [
    "### **SATCAT Data Pipeline: Global Registry Standardization**\n",
    "\n",
    "**Dataset:** CelesTrak Satellite Catalog (SATCAT)\n",
    "**Objective:** Transform raw orbital tracking data into a physics-reconstructed, \"Gold Standard\" global registry.\n",
    "\n",
    "### **The Engineering Challenge**\n",
    "While the SATCAT is the premier source for orbital tracking (location), it presents a significant **Physics Transparency Gap**. While it identifies ~60,000 objects, it is effectively **\"Mass-Blind\"** out of the box.\n",
    "\n",
    "1.  **Ingestion & Schema Alignment:** Normalize headers to snake_case and implement in_orbit logic. \n",
    "2.  **Universal Numeric Sanitization:** Neutralize 0.0 placeholders and enforce strict type-safety.\n",
    "3.  **Keplerian Density Engineering:** Mathematically derive missing orbital periods using Keplerâ€™s Third Law.\n",
    "4.  **High-Fidelity Enrichment:** Synchronize with ucs_cleaned.csv to inject precision mass data for the active fleet.\n",
    "5.  **Tiered Mass Imputation:** Apply ESA-standard proxies for the \"Invisible Population\" (Debris/Rocket Bodies).\n",
    "6.  **Categorical Hardening:** Standardize object types and operational status codes for relational integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8feecfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8bc44",
   "metadata": {},
   "source": [
    "### **Stage 1: Ingestion & Schema Alignment**\n",
    "**The Problem:** The raw SATCAT headers use legacy uppercase formatting (e.g., `NORAD_CAT_ID`), which is inconsistent with our UCS snake_case convention. Furthermore, a \"Gold Standard\" dataset must preserve all original metadata to ensure no information is lost during the standardization process.\n",
    "\n",
    "**The Solution:** * **Global Renaming:** We map critical physical and relational headers to `snake_case` to match the UCS pipeline's \"DNA\".\n",
    "* **Feature Preservation:** We retain 100% of the original columns, only renaming the essential ones for programmatic efficiency.\n",
    "* **In-Orbit Logic:** We introduce the `in_orbit` booleanâ€”a primary feature that separates active kinetic threats from historical decay records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4eb0b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stage 1 Audit ---\n",
      "Total Columns Retained: 18\n",
      "Total Records:         67,464\n",
      "In-Orbit Boolean:      Added (Density: 48.7%)\n"
     ]
    }
   ],
   "source": [
    "raw_registry = pd.read_csv('../data/original/satcat.csv')\n",
    "\n",
    "rename_map = {\n",
    "    'OBJECT_NAME': 'object_name',\n",
    "    'OBJECT_ID': 'cospar_id',            # Perfect Match with UCS\n",
    "    'NORAD_CAT_ID': 'norad_id',          # Perfect Match with UCS\n",
    "    'OBJECT_TYPE': 'object_type',        # Refined in Stage 4\n",
    "    'OPS_STATUS_CODE': 'ops_status',   \n",
    "    'OWNER': 'owner_code',               # To be enriched by UCS 'owner'\n",
    "    'LAUNCH_DATE': 'launch_date',        # Standardized to datetime\n",
    "    'LAUNCH_SITE': 'launch_site',        # Matches UCS\n",
    "    'DECAY_DATE': 'decay_date',\n",
    "    'PERIOD': 'period_minutes',          # Standardized Physics\n",
    "    'INCLINATION': 'inclination_degrees',# Standardized Physics\n",
    "    'APOGEE': 'apogee_km',               # Standardized Physics\n",
    "    'PERIGEE': 'perigee_km',             # Standardized Physics\n",
    "    'RCS': 'rcs',                        # Core for Kinetic Modeling\n",
    "    'DATA_STATUS_CODE': 'data_status', \n",
    "    'ORBIT_CENTER': 'orbit_center',    \n",
    "    'ORBIT_TYPE': 'orbit_type_code'      # Changed to prevent merge collision\n",
    "}\n",
    "\n",
    "# batch rename of all columns to standardized names\n",
    "# that align with UCS where at all possible\n",
    "registry = raw_registry.rename(columns=rename_map).copy()\n",
    "\n",
    "# sets registry['in_orbit'] to 1 if registry['decay_date'] is NaN, sets registry['in_orbit'] to 0 otherwise\n",
    "# this allows us to quickly filter for objects that are still in orbit without having to check for NaN values each time\n",
    "registry['in_orbit'] = registry['decay_date'].isnull().astype(int)\n",
    "\n",
    "print(f\"--- Stage 1 Audit ---\")\n",
    "print(f\"Total Columns Retained: {len(registry.columns)}\")\n",
    "print(f\"Total Records:         {len(registry):,}\")\n",
    "print(f\"In-Orbit Boolean:      Added (Density: {registry['in_orbit'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6411d",
   "metadata": {},
   "source": [
    "### **Stage 1.1: Strategic Ghost Column Audit**\n",
    "**The Problem:** Raw CSV exports often contain \"Ghost Columns\" â€” unpopulated placeholders created by formatting artifacts or trailing delimiters in the original database. These columns inflate memory usage and create \"Wide Data\" noise without adding informational value.\n",
    "\n",
    "**The Solution:** We implement a **Dynamic Artifact Filter** to identify and purge any columns matching the `Unnamed` pattern or those containing 100% null values. This ensures the dataset remains lean and focused on valid orbital attributes while preserving 100% of the legitimate SATCAT metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a5a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ghost Column Audit ---\n",
      "âœ… CLEAN: No ghost columns or 100% null artifacts detected.\n",
      "Relational Integrity Check: PASSED\n"
     ]
    }
   ],
   "source": [
    "# Filter off unwanted columns dynamically to account for version updates\n",
    "\n",
    "# there are multiple columns that are named 'Unnamed: X'\n",
    "# this will dynamically find all such columns\n",
    "unnamed_columns = [col for col in registry.columns if 'Unnamed' in col]\n",
    "\n",
    "# there are multiple columns that are 100% null\n",
    "# this will dynamically find all such columns\n",
    "null_columns = [col for col in registry.columns if registry[col].isnull().all()]\n",
    "\n",
    "# combine both lists to get all of the 'ghost' columns\n",
    "ghost_columns = list(set(unnamed_columns + null_columns))\n",
    "\n",
    "print(\"--- Ghost Column Audit ---\")\n",
    "if ghost_columns:\n",
    "    # if there are any columns in the ghost_columns list, drop them from the registry dataframe\n",
    "    print(f\"Found {len(ghost_columns)} artifact columns: {ghost_columns}\")\n",
    "    registry.drop(columns=ghost_columns, inplace=True)\n",
    "    print(f\"âœ… SUCCESS: Artifacts purged. Remaining columns: {len(registry.columns)}\")\n",
    "else:\n",
    "    print(\"âœ… CLEAN: No ghost columns or 100% null artifacts detected.\")\n",
    "\n",
    "# a list of essential keys that MUST be present in the cleaned registry\n",
    "essential_keys = ['norad_id', 'object_name', 'in_orbit', 'period_minutes', 'perigee_km', 'apogee_km', 'inclination_degrees', 'rcs']\n",
    "\n",
    "# verify that all essential keys are present in the cleaned registry\n",
    "integrity_check = all(key in registry.columns for key in essential_keys)\n",
    "\n",
    "print(f\"Relational Integrity Check: {'PASSED' if integrity_check else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207e9a9",
   "metadata": {},
   "source": [
    "### **Stage 1.2: Pre-Sanitization Health Audit**\n",
    "**The Problem:** Before enforcing physics standardization, we must quantify the scale of the **Transparency Gap** in the raw registry. Treating `0.0` or string artifacts as valid data during initial EDA would lead to a \"Ghost Population\" that appears to have no mass or motion, skewing our baseline risk assessments.\n",
    "\n",
    "**The Solution:** We execute a technical audit to identify \"Non-Physical\" values across our five core attributes. This report tracks:\n",
    "* **String Artifacts:** Non-numeric entries that force columns into `object` types.\n",
    "* **Placeholder Zeros:** Valid numeric `0.0` entries that actually represent missing data in the SATCAT.\n",
    "* **Density Baseline:** The true percentage of \"Physics-Ready\" data available in the raw source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca959f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             --- RAW DATA HEALTH AUDIT ---             \n",
      "Column               | Non-Numeric  | Zeros    | Health %\n",
      "-------------------------------------------------------\n",
      "period_minutes       |          930 |       26 |    98.6%\n",
      "inclination_degrees  |          930 |       34 |    98.6%\n",
      "apogee_km            |          930 |       27 |    98.6%\n",
      "perigee_km           |          930 |       38 |    98.6%\n",
      "rcs                  |       34,533 |        0 |    48.8%\n",
      "-------------------------------------------------------\n",
      "Total Registry Records: 67,464\n",
      "Note: 'Health %' represents records that are both numeric and non-zero.\n"
     ]
    }
   ],
   "source": [
    "# kinetic and geometric attributes\n",
    "physics_cols = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'rcs']\n",
    "\n",
    "print(f\"{'--- RAW DATA HEALTH AUDIT ---':^55}\")\n",
    "print(f\"{'Column':<20} | {'Non-Numeric':<12} | {'Zeros':<8} | {'Health %'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "total_records = len(registry)\n",
    "\n",
    "for col in physics_cols:\n",
    "    if col in registry.columns:\n",
    "        # Count Non-Numeric (Strings/NaNs)\n",
    "        # We try to convert to numeric safely to find what is currently a string\n",
    "        numeric_series = pd.to_numeric(registry[col], errors='coerce')\n",
    "\n",
    "        # step through the columns, check NaNs for each column and determine how many rows are NaN or a string\n",
    "        non_numeric = registry[col].isna().sum() + (registry[col].apply(lambda x: isinstance(x, str))).sum()\n",
    "        \n",
    "        # Count Placeholder Zeros (Numeric 0.0)\n",
    "        # This lets us count how many valid numeric entries are actually zero\n",
    "        # by using the numeric_series we created above and summing where it equals zero\n",
    "        zeros = (numeric_series == 0).sum()\n",
    "        \n",
    "        # Calculate \"Physics-Ready\" Density\n",
    "        # Valid = Not NaN AND Not Zero\n",
    "        valid_count = total_records - (non_numeric + zeros)\n",
    "        health_pct = (valid_count / total_records) * 100\n",
    "        \n",
    "        print(f\"{col:<20} | {non_numeric:>12,} | {zeros:>8,} | {health_pct:>7.1f}%\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "print(f\"Total Registry Records: {total_records:,}\")\n",
    "print(\"Note: 'Health %' represents records that are both numeric and non-zero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8395c89e",
   "metadata": {},
   "source": [
    "### **Stage 2: Universal Numeric & Identifier Sanitization**\n",
    "**The Problem:** High-fidelity orbital modeling requires strict numeric types. However, fields like `rcs`, `period_minutes`, and `perigee_km` often contain `0.0` as a placeholder for \"Unknown\" data. Furthermore, primary identifiers like `norad_id` and `cospar_id` can contain decimal artifacts or hidden whitespace that prevent clean merging.\n",
    "\n",
    "**The Solution:**\n",
    "* **Numeric Coercion:** We apply `pd.to_numeric` across all core physics columns to ensure a stable `float64` foundation.\n",
    "* **Placeholder Neutralization:** We convert `0.0` values to `NaN` to ensure missing data is handled correctly by statistical functions.\n",
    "* **ID Normalization:** We force `norad_id` to a clean integer-string and apply a deep string-scrub to `cospar_id` to ensure 1:1 join-readiness with the UCS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ffcb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitizing 7 attributes...\n",
      "\n",
      "--- Final Sanitization Health Check ---\n",
      "period_minutes       | Nulls:    956 | Type: float64\n",
      "inclination_degrees  | Nulls:    964 | Type: float64\n",
      "apogee_km            | Nulls:    957 | Type: float64\n",
      "perigee_km           | Nulls:    968 | Type: float64\n",
      "rcs                  | Nulls: 34,533 | Type: float64\n",
      "norad_id             | Nulls:      0 | Type: object\n",
      "cospar_id            | Nulls:      0 | Type: object\n",
      "\n",
      "âœ… Stage 2 Complete: Numeric and Identifier integrity enforced.\n"
     ]
    }
   ],
   "source": [
    "# Expanded lists for universal sanitization\n",
    "physics_cols = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'rcs']\n",
    "id_numeric_cols = ['norad_id']\n",
    "id_string_cols = ['cospar_id']\n",
    "\n",
    "print(f\"Sanitizing {len(physics_cols) + len(id_numeric_cols) + len(id_string_cols)} attributes...\")\n",
    "\n",
    "# Standardize Numeric Identifiers\n",
    "for col in id_numeric_cols:\n",
    "    if col in registry.columns:\n",
    "        # Strip decimal artifacts (e.g., 25544.0 -> 25544)\n",
    "        registry[col] = pd.to_numeric(registry[col], errors='coerce')\n",
    "        registry = registry.dropna(subset=[col])\n",
    "        registry[col] = registry[col].astype(int).astype(str)\n",
    "\n",
    "# Standardize String Identifiers\n",
    "for col in id_string_cols:\n",
    "    if col in registry.columns:\n",
    "        # Strip whitespace and normalize case to prevent \"Invisible Bug\" merge failures\n",
    "        registry[col] = registry[col].astype(str).str.strip().str.upper()\n",
    "        # Neutralize 'NAN' strings\n",
    "        registry[col] = registry[col].replace('NAN', np.nan)\n",
    "\n",
    "# Sanitization Loop for Physics (UCS Stage 3.2 & 4.2 Logic)\n",
    "for col in physics_cols:\n",
    "    if col in registry.columns:\n",
    "        # Force to numeric foundation\n",
    "        registry[col] = pd.to_numeric(registry[col], errors='coerce')\n",
    "        \n",
    "        # Neutralize 0.0 placeholders representing 'Missing' data\n",
    "        registry[col] = registry[col].replace(0, np.nan)\n",
    "        \n",
    "        # Enforce Physical Constraints: Geometry cannot be negative\n",
    "        if col != 'rcs':\n",
    "            registry.loc[registry[col] < 0, col] = 0\n",
    "\n",
    "# Verification Diagnostic\n",
    "print(\"\\n--- Final Sanitization Health Check ---\")\n",
    "for col in physics_cols + id_numeric_cols + id_string_cols:\n",
    "    null_count = registry[col].isnull().sum()\n",
    "    dtype = registry[col].dtype\n",
    "    print(f\"{col:<20} | Nulls: {null_count:>6,} | Type: {dtype}\")\n",
    "\n",
    "print(\"\\nâœ… Stage 2 Complete: Numeric and Identifier integrity enforced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef096e38",
   "metadata": {},
   "source": [
    "### **Stage 2.1: High-Fidelity Geometry & Mass Enrichment (UCS Sync)**\n",
    "**The Problem:** Stage 2 identified core orbital elements and a total absence of mass data. While these can be mathematically derived in Stage 3, utilizing verified ground-truth observations from the verified UCS registry provides a higher level of \"Gold Standard\" precision for the active fleet.\n",
    "\n",
    "**The Solution:** We synchronize the SATCAT with `ucs_cleaned.csv` immediately after sanitization. This creates a \"Hierarchy of Truth\" where verified observations from the active satellite registry override SATCAT nulls, repairing the catalog's active population before we resort to secondary Keplerian derivations or statistical proxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8161d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronizing SATCAT with UCS high-fidelity data...\n",
      "\n",
      "            --- RELATIONAL REPAIR AUDIT ---            \n",
      "Attribute            | Repaired   | Final Nulls\n",
      "-------------------------------------------------------\n",
      "period_minutes       |         22 |         934\n",
      "inclination_degrees  |         26 |         938\n",
      "apogee_km            |         23 |         934\n",
      "perigee_km           |         25 |         943\n",
      "\n",
      "          --- FINAL STAGE 2.1 HEALTH GATE ---          \n",
      "Feature              | Type       | Density\n",
      "-------------------------------------------------------\n",
      "norad_id             | object     |    100.0%\n",
      "cospar_id            | object     |    100.0%\n",
      "period_minutes       | float64    |     98.6%\n",
      "inclination_degrees  | float64    |     98.6%\n",
      "apogee_km            | float64    |     98.6%\n",
      "perigee_km           | float64    |     98.6%\n",
      "launch_mass_kg       | float64    |     11.2%\n",
      "-------------------------------------------------------\n",
      "âœ… Stage 2.1 Complete: High-fidelity active fleet data synchronized.\n"
     ]
    }
   ],
   "source": [
    "ucs_path = '../data/clean/ucs_cleaned.csv'\n",
    "ucs_clean = pd.read_csv(ucs_path, dtype={'norad_id': str})\n",
    " \n",
    "repair_cols = [\n",
    "    'norad_id', 'launch_mass_kg', 'period_minutes', \n",
    "    'inclination_degrees', 'apogee_km', 'perigee_km', 'eccentricity'\n",
    "]\n",
    "\n",
    "print(f\"Synchronizing SATCAT with UCS high-fidelity data...\")\n",
    "\n",
    "# left sided merge\n",
    "# append UCS columns with '_ucs' suffix to avoid overwriting existing data unintentionally\n",
    "registry = registry.merge(ucs_clean[repair_cols], on='norad_id', how='left', suffixes=('', '_ucs'))\n",
    "\n",
    "# The Enrichment & Repair Audit\n",
    "enriched_fields = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'eccentricity', 'launch_mass_kg']\n",
    "\n",
    "print(f\"\\n{'--- RELATIONAL REPAIR AUDIT ---':^55}\")\n",
    "print(f\"{'Attribute':<20} | {'Repaired':<10} | {'Final Nulls'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for col in enriched_fields:\n",
    "    ucs_col = f\"{col}_ucs\" if f\"{col}_ucs\" in registry.columns else col\n",
    "    if ucs_col != col:\n",
    "        pre_nulls = registry[col].isnull().sum()\n",
    "        registry[col] = registry[col].fillna(registry[ucs_col])\n",
    "        post_nulls = registry[col].isnull().sum()\n",
    "        repaired = pre_nulls - post_nulls\n",
    "        print(f\"{col:<20} | {repaired:>10,} | {post_nulls:>11,}\")\n",
    "\n",
    "# Clean up temporary UCS columns\n",
    "cols_to_drop = [c for c in registry.columns if c.endswith('_ucs')]\n",
    "registry.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Final Sanitization Health Check (Verbose & Pretty)\n",
    "print(f\"\\n{'--- FINAL STAGE 2.1 HEALTH GATE ---':^55}\")\n",
    "print(f\"{'Feature':<20} | {'Type':<10} | {'Density'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Include identifiers and sanitized physics for the final gate\n",
    "gate_cols = ['norad_id', 'cospar_id', 'period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'launch_mass_kg']\n",
    "\n",
    "for col in gate_cols:\n",
    "    null_count = registry[col].isnull().sum()\n",
    "    density = (1 - (null_count / len(registry))) * 100\n",
    "    dtype = str(registry[col].dtype)\n",
    "    print(f\"{col:<20} | {dtype:<10} | {density:>8.1f}%\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "print(f\"âœ… Stage 2.1 Complete: High-fidelity active fleet data synchronized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3c876",
   "metadata": {},
   "source": [
    "### **Stage 2.2: Timeline Reconstruction**\n",
    "**The Problem:** Standard integer types in pandas cannot store `NaN` values, often forcing years and ages into floating-point formats (e.g., `2026.0`). This creates \"Type Integrity\" errors during final audits and inconsistent data \"smell\" when compared to the UCS registry.\n",
    "\n",
    "**The Solution:** We implement the **nullable integer (`Int64`)** specification. This ensures that `launch_year` and `sat_age_years` are stored as pure integers while preserving the ability to handle missing data without defaulting to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8f1fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Timeline Reconstruction...\n",
      "âœ… Stage 2.2 Complete: Timeline hardened. Average In-Orbit Age: 19.7 years.\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing Timeline Reconstruction...\")\n",
    "\n",
    "# Standardize Dates\n",
    "registry['launch_date'] = pd.to_datetime(registry['launch_date'], errors='coerce')\n",
    "registry['decay_date'] = pd.to_datetime(registry['decay_date'], errors='coerce')\n",
    "\n",
    "# Derive Timeline Attributes\n",
    "registry['launch_year'] = registry['launch_date'].dt.year\n",
    "registry['sat_age_years'] = 2026 - registry['launch_year']\n",
    "\n",
    "# Enforce Nullable Integer Types (The \"Gold Standard\" Fix)\n",
    "# 'Int64' (Capital I) is the pandas-specific type for integers that allow NaNs\n",
    "registry['launch_year'] = registry['launch_year'].astype('Int64')\n",
    "registry['sat_age_years'] = registry['sat_age_years'].astype('Int64')\n",
    "\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "avg_age = registry[in_orbit_mask]['sat_age_years'].mean()\n",
    "print(f\"âœ… Stage 2.2 Complete: Timeline hardened. Average In-Orbit Age: {avg_age:.1f} years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fb1a9",
   "metadata": {},
   "source": [
    "### **Stage 3: Keplerian Reconstruction (The Density Engine)**\n",
    "**The Problem:** Despite being a tracking catalog, many entries possess Perigee and Apogee data but are missing a recorded `period_minutes`. To achieve 100% density for our kinetic models, we cannot rely on incomplete records or \"ghost\" orbits that appear to have no motion.\n",
    "\n",
    "**The Solution:** We implement **Keplerâ€™s Third Law**. By treating Earth's gravitational constant ($\\mu$) and radius as constants, we can mathematically derive the missing periods from the existing orbital geometry. This ensures every object flagged as `in_orbit` is physics-ready for downstream kinetic energy calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bb151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Keplerian Reconstruction...\n",
      "\n",
      "--- Keplerian Audit ---\n",
      "Remaining Missing Periods (In-Orbit): 604\n",
      "Period Density (In-Orbit):           98.2%\n"
     ]
    }
   ],
   "source": [
    "# Earth Constants for Orbital Mechanics\n",
    "earth_radius = 6378.137\n",
    "mu = 398600.4418 # km^3/s^2 (Earth's gravitational parameter)\n",
    "\n",
    "def calculate_kepler_period(row):\n",
    "    \"\"\"\n",
    "    Derives orbital period from altitudes if the period is missing.\n",
    "    Matches the derivation logic used in ucs_cleanup Stage 4.2.\n",
    "    \"\"\"\n",
    "    # Only derive if Period is missing but we have altitudes\n",
    "    if pd.isna(row['period_minutes']) and not pd.isna(row['perigee_km']) and not pd.isna(row['apogee_km']):\n",
    "        # a = semi-major axis (Earth Radius + Average Altitude)\n",
    "        a = earth_radius + ((row['perigee_km'] + row['apogee_km']) / 2)\n",
    "        # T = 2 * pi * sqrt(a^3 / mu)\n",
    "        period_seconds = 2 * np.pi * np.sqrt(a**3 / mu)\n",
    "        return period_seconds / 60\n",
    "    return row['period_minutes']\n",
    "\n",
    "print(\"Executing Keplerian Reconstruction...\")\n",
    "registry['period_minutes'] = registry.apply(calculate_kepler_period, axis=1)\n",
    "\n",
    "# Diagnostic Audit of the In-Orbit Population\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "missing_p = registry[in_orbit_mask]['period_minutes'].isnull().sum()\n",
    "\n",
    "print(f\"\\n--- Keplerian Audit ---\")\n",
    "print(f\"Remaining Missing Periods (In-Orbit): {missing_p}\")\n",
    "print(f\"Period Density (In-Orbit):           {registry[in_orbit_mask]['period_minutes'].notna().mean():.1%}\")\n",
    "\n",
    "if missing_p == 0:\n",
    "    print(\"\\nðŸš€ SUCCESS: 100% Period density achieved for the in-orbit population.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92afd1",
   "metadata": {},
   "source": [
    "### **Stage 3.1: Orbital Classification & Final Period Imputation**\n",
    "**The Problem:** Our Keplerian reconstruction achieved 98.1% density, but 615 objects remain \"Physics-Blind\" because they lack both a recorded period and altitude data. In the UCS pipeline, we addressed similar gaps by leveraging **Grouped Median Imputation**.\n",
    "\n",
    "**The Solution:** * **Regime Classification:** We implement a `classify_orbit` function to group all objects into **LEO, MEO, GEO,** or **High Elliptical** based on their orbital period.\n",
    "* **Peer-Group Imputation:** For the final 615 objects, we fill the missing `period_minutes` using the median value of their respective orbital class. This mirrors the Stage 4.2 logic from the UCS cleanup and ensures 100% density for the in-orbit population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54566fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing final 604 periods...\n",
      "\n",
      "--- Final Physics Density Audit ---\n",
      "Remaining Missing Periods (In-Orbit): 0\n",
      "Final Period Density:                100.0%\n",
      "\n",
      "ðŸš€ SUCCESS: 100% Physics density achieved via Grouped Median Imputation.\n"
     ]
    }
   ],
   "source": [
    "def classify_orbit(period):\n",
    "    \"\"\"\n",
    "    Translates orbital period into standardized regimes.\n",
    "    \"\"\"\n",
    "    if pd.isnull(period) or period <= 0:\n",
    "        return 'UNKNOWN'\n",
    "    elif period < 128:\n",
    "        return 'LEO'\n",
    "    elif 1400 <= period <= 1460:\n",
    "        return 'GEO'\n",
    "    elif 128 <= period < 1400:\n",
    "        return 'MEO'\n",
    "    else:\n",
    "        return 'Elliptical'\n",
    "    \n",
    "# Apply initial orbit classification across the entire registry\n",
    "registry['orbit_class'] = registry['period_minutes'].apply(classify_orbit)\n",
    "\n",
    "# We use the median of the orbit_class to fill the final gaps\n",
    "print(f\"Imputing final {registry[registry['in_orbit'] == 1]['period_minutes'].isnull().sum()} periods...\")\n",
    "\n",
    "# groupby orbit_class and transform to get the median period for each orbit class\n",
    "orbit_medians = registry.groupby('orbit_class')['period_minutes'].transform('median')\n",
    "registry['period_minutes'] = registry['period_minutes'].fillna(orbit_medians)\n",
    "\n",
    "# Global Safety Net (In case orbit_class was 'UNKNOWN')\n",
    "# use the overall median to fill the last of the gaps\n",
    "global_median = registry['period_minutes'].median()\n",
    "registry['period_minutes'] = registry['period_minutes'].fillna(global_median)\n",
    "\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "\n",
    "# filter by in-orbit and count remaining missing periods\n",
    "missing_final = registry[in_orbit_mask]['period_minutes'].isnull().sum()\n",
    "\n",
    "print(f\"\\n--- Final Physics Density Audit ---\")\n",
    "print(f\"Remaining Missing Periods (In-Orbit): {missing_final}\")\n",
    "print(f\"Final Period Density:                {registry[in_orbit_mask]['period_minutes'].notna().mean():.1%}\")\n",
    "\n",
    "if missing_final == 0:\n",
    "    print(\"\\nðŸš€ SUCCESS: 100% Physics density achieved via Grouped Median Imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3458c58",
   "metadata": {},
   "source": [
    "### **Stage 3.2: Final Geometric Sweep**\n",
    "**The Problem:** While our Period density is now at 100%, the underlying geometric attributesâ€”`inclination_degrees`, `apogee_km`, and `perigee_km`â€”still contain the `NaN` values we neutralized in Stage 2. A \"Gold Standard\" dataset requires 100% density across the entire physical profile to support precise kinetic modeling.\n",
    "\n",
    "**The Solution:** Perform a final median sweep across the remaining geometric features. We leverage the `orbit_class` we just engineered to fill these gaps with regime-specific medians, ensuring that an \"Unknown LEO\" object receives the physical characteristics typical of its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f761b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Final Geometric Sweep...\n",
      "\n",
      "        --- FINAL GEOMETRY AUDIT ---         \n",
      "Feature                   | Completeness\n",
      "---------------------------------------------\n",
      "period_minutes            |       100.0%\n",
      "inclination_degrees       |       100.0%\n",
      "apogee_km                 |       100.0%\n",
      "perigee_km                |       100.0%\n",
      "---------------------------------------------\n",
      "ðŸš€ PASS: 100% Geometric density achieved for the in-orbit population.\n"
     ]
    }
   ],
   "source": [
    "sweep_cols = ['inclination_degrees', 'apogee_km', 'perigee_km']\n",
    "\n",
    "print(\"Executing Final Geometric Sweep...\")\n",
    "\n",
    "for col in sweep_cols:\n",
    "    if col in registry.columns:\n",
    "        # Primary Fill: Grouped by the Orbit Class we just created\n",
    "        regime_medians = registry.groupby('orbit_class')[col].transform('median')\n",
    "        registry[col] = registry[col].fillna(regime_medians)\n",
    "        \n",
    "        # Safety Fill: Global Median (for any 'UNKNOWN' regimes)\n",
    "        registry[col] = registry[col].fillna(registry[col].median())\n",
    "\n",
    "print(f\"\\n{'--- FINAL GEOMETRY AUDIT ---':^45}\")\n",
    "print(f\"{'Feature':<25} | {'Completeness'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for col in ['period_minutes'] + sweep_cols:\n",
    "    coverage = registry[registry['in_orbit'] == 1][col].notna().mean()\n",
    "    print(f\"{col:<25} | {coverage:>12.1%}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(\"ðŸš€ PASS: 100% Geometric density achieved for the in-orbit population.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3100bdd",
   "metadata": {},
   "source": [
    "### **Stage 3.3: Integrity Polish & Eccentricity Derivation**\n",
    "**The Problem:** While our altitude and period density are at 100%, the SATCAT is missing an explicit **`eccentricity`** field, which is a core requirement for the kinetic models used in the UCS pipeline. Additionally, **`geo_longitude`** must be neutralized to ensure it doesn't contain string artifacts.\n",
    "\n",
    "**The Solution:** \n",
    "* **Mathematical Derivation:** We derive eccentricity using the formula $e = (r_a - r_p) / (r_a + r_p)$, where $r$ is the distance from the Earth's center. \n",
    "* **Schema Alignment:** We add these features to our final \"Gold Standard\" sweep to ensure 100% parity with the UCS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc92436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving orbital eccentricity...\n",
      "\n",
      "      --- COMPLETE GEOMETRIC AUDIT ---       \n",
      "Feature                   | Completeness\n",
      "---------------------------------------------\n",
      "period_minutes            |       100.0%\n",
      "inclination_degrees       |       100.0%\n",
      "apogee_km                 |       100.0%\n",
      "perigee_km                |       100.0%\n",
      "eccentricity              |       100.0%\n",
      "geo_longitude             |       100.0%\n",
      "---------------------------------------------\n",
      "ðŸš€ PASS: 100% Parity with UCS geometric schema achieved.\n"
     ]
    }
   ],
   "source": [
    "# AI helped me find the formula but the function itself is not complicated.\n",
    "# It is 2 basic math operations and then we return a division result.\n",
    "# but I didn't know the formula.\n",
    "#\n",
    "# ra = apogee distance from Earth's center\n",
    "# rp = perigee distance from Earth's center\n",
    "# Derive Eccentricity\n",
    "# Formula: e = (r_a - r_p) / (r_a + r_p)\n",
    "# where r_a = apogee_km + Earth_radius, r_p = perigee_km + Earth_radius\n",
    "\n",
    "earth_radius = 6378.137\n",
    "\n",
    "def derive_eccentricity(row):\n",
    "    ra = row['apogee_km'] + earth_radius  # Distance from Earth center to apogee\n",
    "    rp = row['perigee_km'] + earth_radius  # Distance from Earth center to perigee\n",
    "    return (ra - rp) / (ra + rp)\n",
    "\n",
    "print(\"Deriving orbital eccentricity...\")\n",
    "registry['eccentricity'] = registry.apply(derive_eccentricity, axis=1)\n",
    "\n",
    "# Initialize geo_longitude if it doesn't exist (to match UCS schema)\n",
    "if 'geo_longitude' not in registry.columns:\n",
    "    registry['geo_longitude'] = np.nan\n",
    "\n",
    "# Final Sweep for the \"Missing Two\"\n",
    "final_sweep = ['eccentricity', 'geo_longitude']\n",
    "\n",
    "for col in final_sweep:\n",
    "    # Grouped Median Fill\n",
    "    regime_medians = registry.groupby('orbit_class')[col].transform('median')\n",
    "    registry[col] = registry[col].fillna(regime_medians)\n",
    "    \n",
    "    # Global Safety Net\n",
    "    # GEO longitude defaults to 0 for non-GEO\n",
    "    registry[col] = registry[col].fillna(0.0)\n",
    "\n",
    "print(f\"\\n{'--- COMPLETE GEOMETRIC AUDIT ---':^45}\")\n",
    "print(f\"{'Feature':<25} | {'Completeness'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "all_geo = ['period_minutes', 'inclination_degrees', 'apogee_km', 'perigee_km', 'eccentricity', 'geo_longitude']\n",
    "for col in all_geo:\n",
    "    coverage = registry[registry['in_orbit'] == 1][col].notna().mean()\n",
    "    print(f\"{col:<25} | {coverage:>12.1%}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(\"ðŸš€ PASS: 100% Parity with UCS geometric schema achieved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57369c54",
   "metadata": {},
   "source": [
    "### **Stage 4: Categorical Hardening & String Scrubbing**\n",
    "**The Problem:** The raw SATCAT utilizes abbreviated codes (e.g., `PAY`, `R/B`) and inconsistent string formatting. Mixed-case entries and trailing whitespacesâ€”\"Invisible Bugs\"â€”can cause silent failures during categorical grouping or when merging with the UCS dataset later in the pipeline.\n",
    "\n",
    "**The Solution:**\n",
    "* **Object Mapping:** We translate raw codes into a controlled vocabulary (`PAYLOAD`, `ROCKET BODY`, `DEBRIS`) to ensure clarity.\n",
    "* **Geopolitical Normalization:** We enforce a strict uppercase and `strip()` operation on `owner_code` and `launch_site` to ensure unique labels for geopolitical analysis.\n",
    "* **Deep Scrub:** We iterate through all text-based columns to neutralize whitespace artifacts and ensure the registry meets our \"Gold Standard\" for data cleanliness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28df6fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing object classifications...\n",
      "Executing Deep Scrub on 11 text columns...\n",
      "\n",
      "--- Categorical Distribution ---\n",
      "object_type\n",
      "DEBRIS         35739\n",
      "PAYLOAD        24763\n",
      "ROCKET BODY     6807\n",
      "UNKNOWN          155\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Stage 4 Complete: 11 columns standardized and scrubbed.\n"
     ]
    }
   ],
   "source": [
    "# Map Object Types to human-readable vocabulary\n",
    "type_map = {\n",
    "    'PAY': 'PAYLOAD', \n",
    "    'R/B': 'ROCKET BODY', \n",
    "    'DEB': 'DEBRIS',\n",
    "    'UNK': 'UNKNOWN'\n",
    "}\n",
    "\n",
    "print(\"Standardizing object classifications...\")\n",
    "registry['object_type'] = registry['object_type'].str.strip().str.upper().map(type_map).fillna('UNKNOWN')\n",
    "\n",
    "# Global String Scrubbing\n",
    "text_cols = registry.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Executing Deep Scrub on {len(text_cols)} text columns...\")\n",
    "for col in text_cols:\n",
    "    registry[col] = registry[col].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Neutralize 'NAN' strings back to proper np.nan\n",
    "registry = registry.replace('NAN', np.nan)\n",
    "\n",
    "print(\"\\n--- Categorical Distribution ---\")\n",
    "print(registry['object_type'].value_counts())\n",
    "\n",
    "print(f\"\\nâœ… Stage 4 Complete: {len(text_cols)} columns standardized and scrubbed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4685b8",
   "metadata": {},
   "source": [
    "### **Stage 4.1: Operational Status Hardening**\n",
    "**The Problem:** Raw tracking data utilizes legacy shorthand for satellite health (e.g., `+` for operational, `-` for non-operational). These codes are insufficient for high-level risk reporting or geopolitical audits.\n",
    "\n",
    "**The Solution:** We map the single-character status codes to standardized, human-readable labels. This ensures that the registry's operational context is immediately accessible and ready for \"Zombie\" identification in the next phase of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d791ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardening operational status codes...\n",
      "\n",
      "--- Operational Status Distribution ---\n",
      "ops_status\n",
      "DECAYED             34626\n",
      "UNKNOWN             16654\n",
      "OPERATIONAL         14287\n",
      "NON-OPERATIONAL      1453\n",
      "PARTIAL               399\n",
      "BACKUP/STANDBY         23\n",
      "EXTENDED MISSION       16\n",
      "STANDBY                 6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Stage 4.1 Complete: Legacy status codes standardized.\n"
     ]
    }
   ],
   "source": [
    "# Map legacy single-character status codes to human-readable labels\n",
    "# Source: CelesTrak SATCAT Legend\n",
    "status_map = {\n",
    "    '+': 'OPERATIONAL',\n",
    "    '-': 'NON-OPERATIONAL',\n",
    "    'P': 'PARTIAL',\n",
    "    'B': 'BACKUP/STANDBY',\n",
    "    'S': 'STANDBY',\n",
    "    'X': 'EXTENDED MISSION',\n",
    "    'D': 'DECAYED'\n",
    "}\n",
    "\n",
    "print(\"Hardening operational status codes...\")\n",
    "\n",
    "# Apply mapping and handle missing values\n",
    "registry['ops_status'] = registry['ops_status'].map(status_map).fillna('UNKNOWN')\n",
    "\n",
    "print(\"\\n--- Operational Status Distribution ---\")\n",
    "print(registry['ops_status'].value_counts())\n",
    "\n",
    "print(\"\\nâœ… Stage 4.1 Complete: Legacy status codes standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1256a8",
   "metadata": {},
   "source": [
    "### **Stage 4.2: Physical Binning (RCS Size Class)**\n",
    "**The Problem:** While we possess numeric Radar Cross Section (RCS) data, high-level auditing and visualization are often more effective when using industry-standard size categories.\n",
    "\n",
    "**The Solution:** We mathematically bin the numeric `rcs` into standard classes: **SMALL** (<0.1 $m^2$), **MEDIUM** (0.1-1.0 $m^2$), and **LARGE** (>1.0 $m^2$). This allows us to track \"Size Distribution\" in the orbital environment alongside raw mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1655e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving size categories from numeric RCS...\n",
      "\n",
      "--- RCS Size Distribution (Derived) ---\n",
      "rcs_class\n",
      "UNKNOWN    34533\n",
      "SMALL      18496\n",
      "LARGE       8515\n",
      "MEDIUM      5920\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Stage 4.3 Complete: Physical size categories derived.\n"
     ]
    }
   ],
   "source": [
    "# basic RCS size categorization\n",
    "# \n",
    "def categorize_rcs(val):\n",
    "    if pd.isna(val): return 'UNKNOWN'\n",
    "    if val < 0.1:    return 'SMALL'\n",
    "    if val < 1.0:    return 'MEDIUM'\n",
    "    return 'LARGE'\n",
    "\n",
    "print(\"Deriving size categories from numeric RCS...\")\n",
    "registry['rcs_class'] = registry['rcs'].apply(categorize_rcs)\n",
    "\n",
    "print(\"\\n--- RCS Size Distribution (Derived) ---\")\n",
    "print(registry['rcs_class'].value_counts())\n",
    "\n",
    "print(\"\\nâœ… Stage 4.3 Complete: Physical size categories derived.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c6c6e",
   "metadata": {},
   "source": [
    "### **Stage 4.3: Geopolitical \"Owner\" Transparency Audit**\n",
    "**The Problem:** Raw tracking catalogs often contain geopolitical artifacts such as trailing whitespaces or inconsistent country codes (e.g., 'US' vs 'USA'). These inconsistencies prevent accurate reporting of \"Kinetic Responsibility\"â€”which nation owns the most mass/risk in a given orbital regime.\n",
    "\n",
    "**The Solution:** We perform a final Geopolitical Audit to verify that the **Stage 4 Deep Scrub** successfully unified the `owner_code` field. This report identifies the top \\\"Orbital Stakeholders\\\" and ensures the categorical data is 100% prepared for relational merging with the UCS registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "801d7e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        --- GEOPOLITICAL STAKEHOLDER AUDIT ---         \n",
      "Rank  | Code       | Object Count    | Share\n",
      "-------------------------------------------------------\n",
      "1     | US         |       16,503 |   50.3%\n",
      "2     | CIS        |        6,706 |   20.4%\n",
      "3     | PRC        |        5,880 |   17.9%\n",
      "4     | UK         |          721 |    2.2%\n",
      "5     | FR         |          649 |    2.0%\n",
      "6     | JPN        |          315 |    1.0%\n",
      "7     | TBD        |          208 |    0.6%\n",
      "8     | IND        |          199 |    0.6%\n",
      "9     | ITSO       |          138 |    0.4%\n",
      "10    | ESA        |          127 |    0.4%\n",
      "-------------------------------------------------------\n",
      "âœ… PASS: 129 unique owner codes verified as standardized.\n"
     ]
    }
   ],
   "source": [
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "top_owners = registry[in_orbit_mask]['owner_code'].value_counts()\n",
    "\n",
    "print(f\"{'--- GEOPOLITICAL STAKEHOLDER AUDIT ---':^55}\")\n",
    "print(f\"{'Rank':<5} | {'Code':<10} | {'Object Count':<15} | {'Share'}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i, (code, count) in enumerate(top_owners.head(10).items(), 1):\n",
    "    share = (count / in_orbit_mask.sum()) * 100\n",
    "    print(f\"{i:<5} | {str(code):<10} | {count:>12,} | {share:>6.1f}%\")\n",
    "\n",
    "unique_codes = registry['owner_code'].dropna().unique()\n",
    "dirty_artifacts = [c for c in unique_codes if str(c) != str(c).strip().upper()]\n",
    "\n",
    "print(\"-\" * 55)\n",
    "if not dirty_artifacts:\n",
    "    print(f\"âœ… PASS: {len(unique_codes)} unique owner codes verified as standardized.\")\n",
    "else:\n",
    "    print(f\"âŒ FAIL: {len(dirty_artifacts)} dirty artifacts detected. Re-run Stage 4 scrub.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f633c",
   "metadata": {},
   "source": [
    "### **Stage 4.4: Payload Vulnerability Report (Pre-Zombie Identification)**\n",
    "**The Problem:** A satellite's operational status code only provides a snapshot of its current health, not its remaining utility. Payloads that are labeled as `OPERATIONAL` but have exceeded a 15-year design life represent \"Next-Generation Zombies\" â€” assets at high risk of sudden failure and loss of control.\n",
    "\n",
    "**The Solution:** We execute a **preliminary vulnerability audit** by cross-referencing `ops_status` with `sat_age_years` using the industry-standard 15-year threshold. This provides a conservative baseline estimate prior to the high-fidelity Zombie identification in `03_orbital_risk_synthesis.ipynb`, which uses actual UCS design-life data.\n",
    "\n",
    "**Note:** This is a SATCAT-only analysis. The final Zombie population will be calculated in the synthesis pipeline using the formula: `sat_age_years > (lifetime_years Ã— 1.10)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e4bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          --- PAYLOAD VULNERABILITY AUDIT ---          \n",
      "Total Operational Payloads:     14,284\n",
      "Aged Assets (>15 Years):        398\n",
      "Vulnerability Rate:             2.8%\n",
      "-------------------------------------------------------\n",
      "\n",
      "Vulnerability Distribution by Orbit:\n",
      "orbit_class\n",
      "LEO           193\n",
      "GEO           154\n",
      "MEO            27\n",
      "UNKNOWN        16\n",
      "ELLIPTICAL      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Stage 4.4 Complete: 398 high-risk active assets identified.\n"
     ]
    }
   ],
   "source": [
    "# Define the Vulnerability Threshold (Industry Standard: 5 - 15 Years)\n",
    "vulnerability_threshold = 15\n",
    "\n",
    "# Isolate Operational Payloads\n",
    "op_payloads_mask = (registry['in_orbit'] == 1) & \\\n",
    "                   (registry['object_type'] == 'PAYLOAD') & \\\n",
    "                   (registry['ops_status'] == 'OPERATIONAL')\n",
    "\n",
    "op_payloads = registry[op_payloads_mask].copy()\n",
    "\n",
    "# Calculate Vulnerability\n",
    "total_op = len(op_payloads)\n",
    "vulnerable_op = op_payloads[op_payloads['sat_age_years'] > vulnerability_threshold]\n",
    "vulnerable_count = len(vulnerable_op)\n",
    "\n",
    "print(f\"{'--- PAYLOAD VULNERABILITY AUDIT ---':^55}\")\n",
    "print(f\"Total Operational Payloads:     {total_op:,}\")\n",
    "print(f\"Aged Assets (>15 Years):        {vulnerable_count:,}\")\n",
    "print(f\"Vulnerability Rate:             {(vulnerable_count/total_op if total_op > 0 else 0):.1%}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Breakdown by Orbit Class\n",
    "if vulnerable_count > 0:\n",
    "    print(\"\\nVulnerability Distribution by Orbit:\")\n",
    "    print(vulnerable_op['orbit_class'].value_counts())\n",
    "\n",
    "print(f\"\\nâœ… Stage 4.4 Complete: {vulnerable_count} high-risk active assets identified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60ad81",
   "metadata": {},
   "source": [
    "### **Stage 5: Tiered Mass Imputation (The Proxy Engine)**\n",
    "**The Problem:** Even after UCS enrichment, a ~82.9% gap remains, primarily composed of Debris and Rocket Bodies. To complete our kinetic model, these objects require a physical baseline.\n",
    "\n",
    "**The Solution:** We initialize `proxy_mass_kg`. We preserve the high-fidelity UCS data where it exists, but fill the remaining `NaN` values using conservative averages from the **European Space Agency (ESA) Space Debris Report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89442bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       --- MASS VALIDATION vs ESA 2025 ---        \n",
      "Total In-Orbit Mass:     14,607 tonnes\n",
      "ESA 2025 Benchmark:      13,600-15,100 tonnes\n",
      "--------------------------------------------------\n",
      "\n",
      "Mass Distribution (Tonnes):\n",
      "PAYLOAD            9,135  ( 62.5%)\n",
      "ROCKET BODY        4,799  ( 32.9%)\n",
      "DEBRIS               668  (  4.6%)\n",
      "UNKNOWN                5  (  0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Initialize proxy_mass_kg with our enriched high-fidelity data\n",
    "# This ensures that UCS-matched satellites keep their real mass.\n",
    "registry['proxy_mass_kg'] = registry['launch_mass_kg']\n",
    "\n",
    "# Object-Type-Specific proxies (ESA-aligned where possible)\n",
    "# Based on ESA 2025 Space Environment Report when published, otherwise conservative assumptions\n",
    "mass_proxies = {\n",
    "    'ROCKET BODY': 2000.0,  # Assumed conservative; ESA 2025 does not publish a class-average\n",
    "    'PAYLOAD': 355.0,       # ESA active payload mean mass (Sec. 3.5, Fig. 2.31)\n",
    "    'DEBRIS': 50.0,         # Trackable fragment assumption; ESA does not provide a mean mass\n",
    "    'UNKNOWN': 100.0        # Conservative fallback for unclassified objects\n",
    "}\n",
    "\n",
    "for category, mass_val in mass_proxies.items():\n",
    "    # Only fill where mass is still missing after the UCS merge\n",
    "    mask = (registry['object_type'] == category) & (registry['proxy_mass_kg'].isna())\n",
    "    registry.loc[mask, 'proxy_mass_kg'] = mass_val\n",
    "\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "total_mass_kg = registry[in_orbit_mask]['proxy_mass_kg'].sum()\n",
    "total_mass_tonnes = total_mass_kg / 1000\n",
    "\n",
    "print(f\"\\n{'--- MASS VALIDATION vs ESA 2025 ---':^50}\")\n",
    "print(f\"Total In-Orbit Mass:     {total_mass_tonnes:,.0f} tonnes\")\n",
    "print(\"ESA 2025 Benchmark:      13,600-15,100 tonnes\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Breakdown by object type\n",
    "mass_by_type = registry[in_orbit_mask].groupby('object_type')['proxy_mass_kg'].sum() / 1000\n",
    "print(\"\\nMass Distribution (Tonnes):\")\n",
    "for obj_type, mass in mass_by_type.sort_values(ascending=False).items():\n",
    "    pct = (mass / total_mass_tonnes) * 100\n",
    "    print(f\"{obj_type:<15} {mass:>8,.0f}  ({pct:>5.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884015d",
   "metadata": {},
   "source": [
    "### **Stage 5.1: Multi-Physics Proxy Imputation**\n",
    "**The Problem:** While Mass is the primary gap, a significant portion of the debris population lacks observed **Inclination** or **RCS**. Without these, we cannot calculate orbital overlap or the cross-sectional area of a potential collision.\n",
    "\n",
    "**The Solution:** We apply \"Peer-Group\" proxies for the remaining geometric gaps. \n",
    "* **Inclination:** We utilize the median inclination of the object's `orbit_class` to fill gaps.\n",
    "* **RCS:** We apply categorical proxies based on `object_type` (e.g., Rocket Bodies are assigned a larger baseline signature than Debris fragments) to ensure 100% density across the kinetic profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0297364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Multi-Physics Proxy Sweep...\n",
      "\n",
      "        --- FINAL PHYSICS DENSITY GATE ---        \n",
      "Attribute                 | Density\n",
      "--------------------------------------------------\n",
      "proxy_mass_kg             |     100.0%\n",
      "period_minutes            |     100.0%\n",
      "inclination_degrees       |     100.0%\n",
      "rcs                       |     100.0%\n",
      "eccentricity              |     100.0%\n",
      "--------------------------------------------------\n",
      "ðŸš€ PASS: All in-orbit assets are physics-complete.\n"
     ]
    }
   ],
   "source": [
    "# Define Physics Proxies for RCS (m^2)\n",
    "rcs_proxies = {\n",
    "    'ROCKET BODY': 5.0,   \n",
    "    'PAYLOAD': 1.0,       \n",
    "    'DEBRIS': 0.01,       \n",
    "    'UNKNOWN': 0.01\n",
    "}\n",
    "\n",
    "print(\"Executing Multi-Physics Proxy Sweep...\")\n",
    "\n",
    "# Impute RCS\n",
    "for category, rcs_val in rcs_proxies.items():\n",
    "    mask = (registry['object_type'] == category) & (registry['rcs'].isna())\n",
    "    registry.loc[mask, 'rcs'] = rcs_val\n",
    "\n",
    "# Impute Inclination (Using Orbit Class Medians)\n",
    "if registry['inclination_degrees'].isnull().any():\n",
    "    inc_medians = registry.groupby('orbit_class')['inclination_degrees'].transform('median')\n",
    "    registry['inclination_degrees'] = registry['inclination_degrees'].fillna(inc_medians)\n",
    "    registry['inclination_degrees'] = registry['inclination_degrees'].fillna(registry['inclination_degrees'].median())\n",
    "\n",
    "physics_gate = ['proxy_mass_kg', 'period_minutes', 'inclination_degrees', 'rcs', 'eccentricity']\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "\n",
    "print(f\"\\n{'--- FINAL PHYSICS DENSITY GATE ---':^50}\")\n",
    "print(f\"{'Attribute':<25} | {'Density'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for col in physics_gate:\n",
    "    density = registry[in_orbit_mask][col].notna().mean()\n",
    "    print(f\"{col:<25} | {density:>10.1%}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "if registry[in_orbit_mask][physics_gate].isnull().sum().sum() == 0:\n",
    "    print(\"ðŸš€ PASS: All in-orbit assets are physics-complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9f57e",
   "metadata": {},
   "source": [
    "### **Stage 5.2: Dry Mass Derivation & Fuel Fraction Audit**\n",
    "**The Problem:** High-fidelity de-orbit modeling and collision analysis require a distinction between **Wet Mass** (Launch) and **Dry Mass** (End-of-Life). Using launch mass for inactive debris or exhausted rocket bodies overestimates the kinetic energy present in the orbital environment.\n",
    "\n",
    "**The Solution:** We derive `dry_mass_kg` by applying industry-standard fuel fraction ratios.\n",
    "* **Payloads:** 0.65 ratio for LEO (35% fuel); 0.55 for GEO/MEO/Elliptical (45% fuel for station-keeping).\n",
    "* **Debris & Rocket Bodies:** 1.0 ratio (representing 100% structural dry mass).\n",
    "\n",
    "**Note:** This differs from the UCS methodology (Stage 4.1), which uses observed median ratios from existing satellites. The SATCAT approach applies conservative industry standards to the broader debris population lacking empirical dry mass observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e539876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving dry mass estimates...\n",
      "\n",
      "         --- DRY MASS INTEGRITY AUDIT ---         \n",
      "Metric                    | Value\n",
      "--------------------------------------------------\n",
      "Total Wet Mass (MT)       | 14,607\n",
      "Total Dry Mass (MT)       | 12,562\n",
      "Aggregate Fuel Load       | 2,045 MT\n",
      "--------------------------------------------------\n",
      "ðŸš€ PASS: Dry mass derived with 100% physical integrity.\n"
     ]
    }
   ],
   "source": [
    "def calculate_dry_mass(row):\n",
    "    \"\"\"\n",
    "    Applies orbit-specific mass ratios to derive dry mass from proxy_mass_kg.\n",
    "\n",
    "    Update: Logic updated to match a more conservative fuel-fraction model\n",
    "    based on recent literature (ESA 2025 Space Environment Report).\n",
    "    \"\"\"\n",
    "    wet_mass = row['proxy_mass_kg']\n",
    "    obj_type = row['object_type']\n",
    "    regime = row['orbit_class']\n",
    "    \n",
    "    # Station-Keeping: The act of maintaining a satellite's orbit.\n",
    "    # Typically requires small amounts of fuel for minor adjustments to keep\n",
    "    # the satellite in its intended orbit. Satellites are affected by a variety\n",
    "    # of external factors requiring periodic thruster adjustments.\n",
    "\n",
    "    # Debris and Rocket Bodies are essentially dry structures (no fuel)\n",
    "    if obj_type in ['DEBRIS', 'ROCKET BODY']:\n",
    "        return wet_mass \n",
    "    \n",
    "    # Payloads follow orbit-specific fuel-fraction logic\n",
    "    if obj_type == 'PAYLOAD':\n",
    "        if regime == 'LEO':\n",
    "            # LEO satellites typically carry minimal fuel (<10%). They carried into orbit\n",
    "            # by a launch vehicle and use small propulsion for station-keeping (minor delta-v \n",
    "            # thruster adjustments to keep the satellite from drifting out of its intended orbit).\n",
    "            # Conservative estimate: 90% Dry Mass.\n",
    "            return wet_mass * 0.90\n",
    "        else:\n",
    "            # GEO/MEO/Deep Space satellites often require significant fuel reserves\n",
    "            # to reach and maintain their orbits, as well as for station-keeping maneuvers\n",
    "            # Standard estimate: 55% Dry Mass.\n",
    "            return wet_mass * 0.55\n",
    "            \n",
    "    return wet_mass\n",
    "\n",
    "print(\"Deriving dry mass estimates...\")\n",
    "registry['dry_mass_kg'] = registry.apply(calculate_dry_mass, axis=1)\n",
    "\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "total_wet = registry[in_orbit_mask]['proxy_mass_kg'].sum() / 1000\n",
    "total_dry = registry[in_orbit_mask]['dry_mass_kg'].sum() / 1000\n",
    "\n",
    "print(f\"\\n{'--- DRY MASS INTEGRITY AUDIT ---':^50}\")\n",
    "print(f\"{'Metric':<25} | {'Value'}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Total Wet Mass (MT)':<25} | {total_wet:,.0f}\")\n",
    "print(f\"{'Total Dry Mass (MT)':<25} | {total_dry:,.0f}\")\n",
    "print(f\"{'Aggregate Fuel Load':<25} | {total_wet - total_dry:,.0f} MT\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "phys_errors = (registry[in_orbit_mask]['dry_mass_kg'] <= 0).sum()\n",
    "if phys_errors == 0:\n",
    "    print(\"ðŸš€ PASS: Dry mass derived with 100% physical integrity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d4e2e",
   "metadata": {},
   "source": [
    "## **Cleaned SATCAT Registry: Data Dictionary**\n",
    "\n",
    "#### **1. Physical & Kinetic Properties (Reconstructed)**\n",
    "These columns represent the \"Kinetic Engine\" of the simulation. Gaps have been filled using high-fidelity UCS enrichment and **ESA-standard proxies**.\n",
    "\n",
    "| Feature Name | Type | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| `launch_mass_kg` | `float` | High-fidelity mass pulled from the **UCS Registry**. Remains `NaN` for debris. |\n",
    "| `proxy_mass_kg` | `float` | **Final Kinetic Mass.** Uses high-fi UCS data or ESA categorical proxies. |\n",
    "| `dry_mass_kg` | `float` | **Structural Mass.** Derived using orbit-specific Dry-to-Wet ratios (Stage 5.2). |\n",
    "| `rcs` | `float` | Radar Cross Section ($m^2$). Sanitized and imputed via categorical baselines. |\n",
    "| `rcs_class` | `str` | Derived size bin: **SMALL, MEDIUM, LARGE**. Based on numeric RCS. |\n",
    "| `sat_age_years` | `Int64` | Calculated age ($2026 - launch\\_year$) for fragmentation modeling. |\n",
    "\n",
    "#### **2. Orbital Mechanics (Keplerian Verified)**\n",
    "The geometry of the global tracked population. All entries are now physics-dense.\n",
    "\n",
    "| Feature Name | Type | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| `period_minutes` | `float` | Time for one orbit. **Derived via Kepler's 3rd Law** ($T = 2\\pi\\sqrt{a^3/\\mu}$). |\n",
    "| `inclination_degrees` | `float` | Angle relative to equator. Essential for collision probability maps. |\n",
    "| `apogee_km` | `float` | Highest altitude point in orbit. |\n",
    "| `perigee_km` | `float` | Lowest altitude point in orbit. |\n",
    "| `eccentricity` | `float` | Deviation from circularity. **Mathematically derived** from altitudes. |\n",
    "| `orbit_class` | `str` | Standardized regime: **LEO, MEO, GEO, Elliptical**. |\n",
    "\n",
    "#### **3. Categorical & Temporal Metadata**\n",
    "Standardized labels for relational integrity and geopolitical risk analysis.\n",
    "\n",
    "| Feature Name | Type | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| `norad_id` | `str` | **Primary Merge Key.** Normalized string for 1:1 join-readiness. |\n",
    "| `cospar_id` | `str` | International designator (COSPAR ID). Scrubbed and capitalized. |\n",
    "| `object_type` | `str` | **Controlled Vocabulary.** `PAYLOAD`, `ROCKET BODY`, `DEBRIS`, `UNKNOWN`. |\n",
    "| `ops_status` | `str` | Human-readable health status (e.g., `OPERATIONAL`, `NON-OPERATIONAL`). |\n",
    "| `owner_code` | `str` | ISO-style country/org code. Stripped of whitespace artifacts. |\n",
    "| `launch_year` | `Int64` | **Derived Year of Launch.** Used for simulation aging. |\n",
    "| `in_orbit` | `int` | Flag: `1` if currently active in orbit, `0` if decayed. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7685a8",
   "metadata": {},
   "source": [
    "### **Stage 6.1: Executive Pipeline Report**\n",
    "**The Goal:** We generate a high-fidelity summary of the standardized registry. This report quantifies the \"Density Gain\" achieved through our physics reconstruction and identifies the core population of \"Next-Generation Zombies\" prior to the synthesis merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cce77b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### **SATCAT Pipeline Completion Report**\n",
       "**Total Global Registry:** 67,464 Objects Tracked\n",
       "\n",
       "#### **Tracking Timeline Summary**\n",
       "| Metric | Value |\n",
       "| :--- | :--- |\n",
       "| **Oldest Catalog Entry** | 1957 |\n",
       "| **Newest Catalog Entry** | 2026 |\n",
       "| **Operational History** | 69 Years |\n",
       "\n",
       "#### **Orbital Environment Health & Risk**\n",
       "| Metric | Value | Note |\n",
       "| :--- | :--- | :--- |\n",
       "| **Average Object Age** | 19.7 Years | Simulation Year: 2026 |\n",
       "| **Total Kinetic Mass** | 14,607 MT | High-Fi UCS + ESA Proxies |\n",
       "| **Total Structural Mass**| 12,562 MT | Derived Dry-Mass (Stage 5.2) |\n",
       "| **Vulnerability Rate** | 2.8% | Operational Payloads > 15 Years |\n",
       "\n",
       "#### **Global Object Composition (In-Orbit)**\n",
       "| Category | Count | Share |\n",
       "| :--- | :--- | :--- |\n",
       "| **Payloads** | 17,730 | 54.0% |\n",
       "| **Rocket Bodies** | 2,402 | 7.3% |\n",
       "| **Debris** | 12,654 | 38.5% |\n",
       "\n",
       "#### **Data Quality and Density Engineering**\n",
       "| Feature | Completeness | Method | Status |\n",
       "| :--- | :--- | :--- | :--- |\n",
       "| **Norad Id** | **100.0%** | Sanitized/Verified | âœ… SUCCESS |\n",
       "| **Cospar Id** | **100.0%** | Sanitized/Verified | âœ… SUCCESS |\n",
       "| **Object Type** | **100.0%** | Standardized/Mapped | âœ… SUCCESS |\n",
       "| **Period Minutes** | **100.0%** | Derived/Calculated | âœ… SUCCESS |\n",
       "| **Inclination Degrees** | **100.0%** | Grouped Median | âœ… SUCCESS |\n",
       "| **Rcs** | **100.0%** | Grouped Median | âœ… SUCCESS |\n",
       "| **Proxy Mass Kg** | **100.0%** | UCS Enriched/Proxy | âœ… SUCCESS |\n",
       "| **Dry Mass Kg** | **100.0%** | UCS Enriched/Proxy | âœ… SUCCESS |\n",
       "| **Orbit Class** | **100.0%** | Standardized/Mapped | âœ… SUCCESS |\n",
       "| **Launch Year** | **100.0%** | Derived/Calculated | âœ… SUCCESS |\n",
       "| **Sat Age Years** | **100.0%** | Derived/Calculated | âœ… SUCCESS |\n",
       "| **Owner Code** | **100.0%** | Sanitized/Verified | âœ… SUCCESS |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… EXPORT SUCCESS: 67,464 records saved to ../data/clean/satcat_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate Final Report Metrics\n",
    "total_rows = len(registry)\n",
    "in_orbit_mask = registry['in_orbit'] == 1\n",
    "in_orbit_count = in_orbit_mask.sum()\n",
    "\n",
    "# Count object types for the Composition Table\n",
    "payload_count = (registry[in_orbit_mask]['object_type'] == 'PAYLOAD').sum()\n",
    "rb_count = (registry[in_orbit_mask]['object_type'] == 'ROCKET BODY').sum()\n",
    "debris_count = (registry[in_orbit_mask]['object_type'] == 'DEBRIS').sum()\n",
    "\n",
    "# Mass Metrics (Wet vs Dry)\n",
    "total_mass_mt = registry[in_orbit_mask]['proxy_mass_kg'].sum() / 1000\n",
    "total_dry_mt = registry[in_orbit_mask]['dry_mass_kg'].sum() / 1000\n",
    "\n",
    "# Health & Vulnerability Metrics\n",
    "avg_age = registry[in_orbit_mask]['sat_age_years'].mean()\n",
    "vulnerability_rate = (vulnerable_count / total_op) if total_op > 0 else 0\n",
    "\n",
    "# Timeline Range\n",
    "earliest_launch = int(registry['launch_year'].min())\n",
    "latest_launch = int(registry['launch_year'].max())\n",
    "\n",
    "# Define features for the Quality and Density Audit\n",
    "physics_features = [\n",
    "    'norad_id', 'cospar_id', 'object_type',            \n",
    "    'period_minutes', 'inclination_degrees', 'rcs',    \n",
    "    'proxy_mass_kg', 'dry_mass_kg', 'orbit_class',     \n",
    "    'launch_year', 'sat_age_years', 'owner_code'       \n",
    "]\n",
    "\n",
    "# Generate Markdown Report\n",
    "report = f\"\"\"\n",
    "### **SATCAT Pipeline Completion Report**\n",
    "**Total Global Registry:** {total_rows:,} Objects Tracked\n",
    "\n",
    "#### **Tracking Timeline Summary**\n",
    "| Metric | Value |\n",
    "| :--- | :--- |\n",
    "| **Oldest Catalog Entry** | {earliest_launch} |\n",
    "| **Newest Catalog Entry** | {latest_launch} |\n",
    "| **Operational History** | {latest_launch - earliest_launch} Years |\n",
    "\n",
    "#### **Orbital Environment Health & Risk**\n",
    "| Metric | Value | Note |\n",
    "| :--- | :--- | :--- |\n",
    "| **Average Object Age** | {avg_age:.1f} Years | Simulation Year: 2026 |\n",
    "| **Total Kinetic Mass** | {total_mass_mt:,.0f} MT | High-Fi UCS + ESA Proxies |\n",
    "| **Total Structural Mass**| {total_dry_mt:,.0f} MT | Derived Dry-Mass (Stage 5.2) |\n",
    "| **Vulnerability Rate** | {vulnerability_rate:.1%} | Operational Payloads > 15 Years |\n",
    "\n",
    "#### **Global Object Composition (In-Orbit)**\n",
    "| Category | Count | Share |\n",
    "| :--- | :--- | :--- |\n",
    "| **Payloads** | {payload_count:,} | {payload_count/in_orbit_count:.1%} |\n",
    "| **Rocket Bodies** | {rb_count:,} | {rb_count/in_orbit_count:.1%} |\n",
    "| **Debris** | {debris_count:,} | {debris_count/in_orbit_count:.1%} |\n",
    "\n",
    "#### **Data Quality and Density Engineering**\n",
    "| Feature | Completeness | Method | Status |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for feature in physics_features:\n",
    "    coverage = registry[in_orbit_mask][feature].notna().mean()\n",
    "    \n",
    "    if feature in ['norad_id', 'cospar_id', 'owner_code']:\n",
    "        method = \"Sanitized/Verified\"\n",
    "    elif feature in ['period_minutes', 'sat_age_years', 'launch_year']:\n",
    "        method = \"Derived/Calculated\"\n",
    "    elif feature in ['object_type', 'orbit_class', 'rcs_class']:\n",
    "        method = \"Standardized/Mapped\"\n",
    "    elif feature in ['proxy_mass_kg', 'dry_mass_kg']:\n",
    "        method = \"UCS Enriched/Proxy\"\n",
    "    else:\n",
    "        method = \"Grouped Median\"\n",
    "        \n",
    "    report += f\"| **{feature.replace('_', ' ').title()}** | **{coverage:.1%}** | {method} | âœ… SUCCESS |\\n\"\n",
    "\n",
    "display(Markdown(report))\n",
    "\n",
    "output_path = '../data/clean/satcat_cleaned.csv'\n",
    "registry.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… EXPORT SUCCESS: {len(registry):,} records saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
